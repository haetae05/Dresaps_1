[Dresaps] Domain 13: Infrastructure - Section 1. Global Architecture & Network

작성일: 2026-02-08
전제 조건: No Credit Card (Supabase Free + Firebase Spark + Expo Free).
목표: 지구 반대편에서도 100ms 이내 응답, 패킷 손실률 0%에 수렴하는 통신 환경 구축.

1.1 통신 표준 및 프로토콜 (Protocol Strategy)

[1단계: 기초 공사] The Standard (필수 구현)

  - 1. [N-01] HTTP/3 강제 vs 구형 안드로이드 호환성:
      - Conflict: 인프라(D13)는 HTTP/3(QUIC)를 강제하지만, 구형 안드로이드(OS 9 이하)의 기본 네트워크 스택은 이를 지원하지 않아 Handshake 실패율이 높음.
      - Resolution Strategy: [Google Play Services Cronet Provider]
      - 구체적 구현 (Implementation):
          - 앱에 OkHttp나 Cronet 라이브러리 전체를 포함시키지 않습니다 (APK 용량 5MB 절약).
          - 앱 실행 시점(Application.onCreate)에 CronetProviderInstaller.installProvider(context)를 호출합니다.
          - Fallback 로직: 구글 플레이 서비스가 없는 기기(중국 등)일 경우에만 예외적으로 내장된 경량 Cronet 엔진을 로드하도록 분기 처리합니다.
          - QUIC Hint: API 요청 시 addQuicHint("api.dresaps.com", 443, 443)를 명시하여 TCP Handshake(3-way)를 생략하고 바로 0-RTT 연결을 시도합니다.
      - 효율(Efficiency): 앱 용량 증가 0KB. OS 레벨 최적화 사용.
      - 안전성(Safety): 구글이 안드로이드 OS 업데이트마다 보안 패치를 자동 적용하므로 유지보수 불필요.
  - 5. [N-05] 로컬 시간 리셋(00:00) vs UTC 서버 원칙:
      - Conflict: DB는 UTC 기준이라 한국 시간 00:00(UTC 15:00) 쿼리를 날릴 때마다 CONVERT_TZ 연산 부하 발생.
      - Resolution Strategy: [Pre-Computed UTC Scalar Injection]
      - 구체적 구현 (Implementation):
          - 절대 원칙: SQL 쿼리문 안에는 NOW(), CURRENT_DATE, timezone() 함수를 절대 쓰지 않습니다.
          - 앱 서버(Python) 메모리에서 target_kst = now(KST).replace(hour=0)를 계산합니다.
          - 이를 UTC 문자열("2026-02-09T15:00:00Z")로 변환합니다.
          - SQL: SELECT * FROM missions WHERE created_at > '2026-02-09T15:00:00Z' (단순 문자열 비교).
      - 효율(Efficiency): DB가 날짜 연산을 전혀 하지 않고, 인덱스(Index)를 바로 타므로 조회 속도 10배 향상.
      - 안전성(Safety): 글로벌 서비스 확장 시, 앱 로직만 바꾸면 되므로 DB 마이그레이션 불필요.
  - 압축 전송 (Compression):
      - Spec: 모든 API JSON 응답은 Brotli (1순위) 또는 Gzip (2순위) 강제 압축.
      - Implementation: Edge Function 응답 헤더에 Content-Encoding: br 설정 및 Body 압축 로직 포함.

[2단계: 확장 및 자동화] Smart Adaptation (지능형 적응)

  - Network Awareness (네트워크 인지 로직):
      - Client Logic: NetInfo (React Native Community) 라이브러리를 사용하여 유저의 네트워크 상태(WiFi vs Cellular) 감지.
      - Action:
          - WiFi: 고해상도 이미지 및 3D 모델 프리로딩 허용.
          - Cellular (Low Data Mode): 이미지 품질 자동 저하(q=60), 동영상 자동 재생 차단, 3D 모델 로딩 지연(Lazy Load).
  - Optimistic UI with Rollback (낙관적 UI 고도화):
      - Advanced Logic: 단순 UI 반영뿐만 아니라, Queueing 시스템 도입.
      - Offline Support: 오프라인 상태에서 누른 '좋아요'는 로컬 스토리지 큐에 저장되었다가, 네트워크 연결 시 자동 재전송(Replay).

[3단계: 보안 심화 및 최적화] Fortress Shield (철벽 방어)

  - TLS 1.3 강제 (암호화 강화):
      - Spec: 구버전 TLS(1.0, 1.1) 연결 시도 시 핸드셰이크 단계에서 즉시 연결 거부 (RST 패킷 전송).
      - Effect: 중간자 공격(MITM) 원천 차단 및 핸드셰이크 속도 30% 향상.
  - 2. [N-02] HSTS 2년 설정 vs 로컬 개발(Localhost) 차단:
      - Conflict: 인프라 헤더(Strict-Transport-Security)를 한 번이라도 본 브라우저는 localhost 접속 시에도 HTTPS를 강제하여, 인증서가 없는 로컬 서버 접속을 원천 차단함.
      - Resolution Strategy: [Local Root CA Injection (mkcert)]
      - 구체적 구현 (Implementation):
          - mkcert 도구를 사용해 개발자 PC 전용 **"사설 루트 인증기관(Local CA)"**을 생성합니다.
          - 이 CA로 서명된 localhost 전용 SSL 인증서(cert.pem, key.pem)를 발급합니다.
          - Python/Node.js 로컬 서버 구동 시 이 인증서를 로드하여 HTTPS://localhost:3000으로 띄웁니다.
          - 개발자의 브라우저와 안드로이드 에뮬레이터에 이 CA를 '신뢰할 수 있는 인증서'로 등록합니다.
      - 효율(Efficiency): 코드 변경 없음. 환경 설정(Config)만으로 해결.
      - 안전성(Safety): 이 인증서는 해당 개발자 PC 밖에서는 종잇조각이므로 유출되어도 보안 위협 0%.

1.2 트래픽 제어 및 라우팅 (Traffic Control)

[1단계: 기초 공사] Rate Limiting (기본 방어)

  - API Rate Limit:
      - General API: IP당 분당 100회 (100 req/min) 제한.
      - AI Generation: IP당 분당 10회 (10 req/min) 제한. (비용 폭탄 원천 차단).
      - Implementation: public.rate_limits 테이블을 활용한 원자적(Atomic) 카운팅. (Redis 대용).
  - Hell Gate Latency (평판 기반 지옥 체험) [NEW]:
      - Target: 악성 유저 및 어뷰저 참교육 (점수 < 75).
      - Safety Protocol (자폭 방지):
          1. **Pre-DB Check**: DB 연결을 맺기 전, JWT 토큰 내부의 `metadata`나 Redis 캐시에서 점수를 확인합니다. (DB 커넥션 점유 0초).
          2. **Client-Side Penalty**: 서버에서 재우지 않고, 응답 헤더에 `X-Penalty-Wait: 3000`을 실어 보냅니다.
          3. **App Logic**: 클라이언트(앱) 네트워킹 레이어에서 이 헤더가 있으면 **스스로 3초간 멈춘 뒤(Thread Sleep)** 결과를 보여줍니다.
      - Effect: 
          - 서버 비용: 0원 증가 (즉시 응답).
          - DB 부하: 0 증가 (연결 안 함).
          - 유저 체감: 앱이 3초간 멈추는 "렉 걸린 경험"을 100% 동일하게 제공.
          - 회피 불가: 앱 변조를 시도해도 서버가 데이터를 3초 늦게 주는 게 아니라 "너 3초 쉬어"라고 명령하는 것이므로, 정상적인 이용이 불가능함.

[2단계: 확장 및 자동화] Geo-Routing & Blocking (지리적 제어)

  - Geo-Routing (로컬라이제이션 준비):
      - Spec: Edge Function 진입 시 헤더의 CF-IPCountry (Cloudflare) 또는 x-client-info를 파싱.
      - Action: 접속 국가 코드를 클라이언트에 내려주어, 앱 실행 시 해당 국가의 언어/통화/트렌드로 자동 세팅.
  - Geo-Blocking (비즈니스 미대상 국가 차단):
      - Logic: 서비스 대상이 아닌 고위험 국가(러시아, 북한 등)에서의 접속 시도 감지 시, DB 쿼리 전 단계인 Edge Function에서 403 Forbidden 리턴. (DB 리소스 낭비 방지).

[3단계: 보안 심화 및 최적화] Intelligent WAF (지능형 방화벽)

  - 3. [N-03] WAF 봇 차단 vs Python 백엔드 통신:
      - Conflict: Python requests 라이브러리는 헤더 순서와 TLS 지문(JA3 Fingerprint)이 브라우저와 달라 WAF에 의해 즉시 차단됨.
      - Resolution Strategy: [Ordered Header & Cipher Suite Mimicry]
      - 구체적 구현 (Implementation):
          - 단순 requests 대신, TLS 레벨 조작이 가능한 curl_cffi 또는 httpx의 HTTP/2 모드를 사용합니다.
          - 헤더 순서 강제: Host -> Connection -> Sec-Ch-Ua -> User-Agent 순서를 크롬 브라우저와 100% 동일하게 하드코딩합니다. (일반 딕셔너리는 순서가 섞임)
          - Cipher Suite 지정: TLS Handshake 시 사용하는 암호화 알고리즘 목록을 최신 크롬 버전이 사용하는 리스트로 고정하여 전송합니다.
      - 효율(Efficiency): 셀레니움 같은 헤드리스 브라우저 대비 메모리 소모량 1/50.
      - 안전성(Safety): WAF 입장에서는 완벽한 '크롬 브라우저'로 보이므로 차단 불가능.
  - 4. [N-04] App Attestation vs Web Studio 접근:
      - Conflict: 인프라 방화벽은 '모바일 앱 무결성 토큰'이 없으면 접근을 막음. 웹(PC Studio)은 이 토큰 생성이 불가능.
      - Resolution Strategy: [Cross-Platform Trust Federation]
      - 구체적 구현 (Implementation):
          - 백엔드 진입점에 **[Unified Guard Middleware]**를 배치합니다.
          - 요청 헤더의 X-Client-Type을 검사합니다.
          - Type이 App이면: Play Integrity API 토큰 검증.
          - Type이 Web이면: reCAPTCHA Enterprise v3 점수 검증 (Score 0.9 이상 통과).
          - 인프라 방화벽에는 "특정 API 경로(/api/studio/*)는 WAF 검사를 완화하고 애플리케이션에 위임한다"는 예외 규칙 하나만 설정합니다.
      - 효율(Efficiency): 단일 미들웨어에서 두 플랫폼 인증을 통합 처리.
 - 5. [N-06] PC Studio 인증 사각지대 vs API 대량 공격:
      - Conflict: PC 프로그램은 앱 무결성(Play Integrity)이나 웹 캡차(reCAPTCHA)를 탑재하기 어려워, 해커가 이를 모방해 '가면 등록 API'를 무한 호출할 수 있음. [cite: 40-41]
      - Resolution Strategy: [Hardware-Bound Signature (HWID 서명)]
      - 구체적 구현 (Implementation):
          - Identity: PC 프로그램 실행 시 CPU/메인보드 시리얼과 시간을 조합한 고유 해시(HWID)를 생성합니다.
          - Sign: 요청 헤더에 `X-PC-Signature: HMAC(HWID + Timestamp, Secret_Key)`를 포함합니다.
          - Guard: 인프라 미들웨어는 "사장님이 배포한 바이너리"에서 생성된 서명이 아니거나, 타임스탬프가 5초 이상 차이 나면 403 Forbidden을 리턴합니다.
          - Throttle: IP가 아닌 **HWID 기준**으로 분당 5회 업로드 제한을 걸어, PC방 등 공용 IP 환경에서의 선의의 피해를 막고 공격자만 차단합니다. [cite: 30]
      - 안전성(Safety): 프로그램이 변조되면 서명 값이 달라져 서버 접근이 원천 차단됨.

1.3 CDN 및 엣지 캐싱 전략 (Edge Strategy)

[1단계: 기초 공사] Static Asset Caching

  - Global CDN:
      - Spec: Supabase Storage CDN (AWS CloudFront 기반) 활용.
      - Policy: 이미지, 폰트, JS 번들 등 정적 자원은 무조건 CDN을 거쳐서 서빙.
  - Cache-Control:
      - Mutable (변경 가능): public, max-age=3600 (1시간).
      - Immutable (변경 불가): public, max-age=31536000, immutable (1년).

[2단계: 확장 및 자동화] Smart Invalidation (지능형 갱신)

  - Versioning Strategy:
      - Logic: 파일명에 해시값이나 버전 번호 포함 (image_v1.webp, image_v2.webp).
      - Effect: CDN 캐시 무효화(Invalidation) 요청 없이도, 파일명이 바뀌면 즉시 새로운 파일이 서빙됨. (비용 0원).
  - Stale-While-Revalidate:
      - Header: Cache-Control: s-maxage=60, stale-while-revalidate=300.
      - Effect: 캐시가 만료되어도 일단 옛날 데이터를 보여주고(속도 빠름), 뒤에서 몰래 최신 데이터를 받아와서 교체.

[3단계: 보안 심화 및 최적화] Private Content Protection

  - Signed URL (서명된 URL):
      - Target: user_measurements (신체 정보) 등 민감 파일.
      - Logic: Public URL 접근을 막고, 오직 인증된 유저만이 5분간 유효한 Signed URL을 발급받아 접근.
      - Implementation: supabase.storage.from('bucket').createSignedUrl(path, 60).

✅ [Section 1. 최종 검수 체크리스트]

1.  [ ] [Protocol] HTTP/3가 활성화되어 있고, 핸드오버 테스트(WiFi ↔ LTE 전환) 시 끊김이 없는가?
2.  [ ] [Time] DB에 저장된 모든 날짜가 Z로 끝나는 UTC 포맷인가?
3.  [ ] [Network Aware] LTE 환경에서 고화질 동영상 재생이 자동으로 차단되는가?
4.  [ ] [Rate Limit] 1분 안에 101번 API를 호출했을 때 429 에러가 뜨는가?
5.  [ ] [Attestation] X-App-Signature 헤더를 조작해서 보냈을 때 서버가 거부하는가?
6.  [ ] [Security] 신체 정보 이미지 URL을 복사해서 시크릿 모드 브라우저에 붙여넣었을 때 403이 뜨는가?


[Dresaps] Domain 13: Infrastructure - Section 2. Database & Security

작성일: 2026-02-08
전제 조건: No Credit Card (Supabase Free Tier).
목표: 해킹 불가능(Zero Trust), 무한 확장(Scalable), 완전 자동화(Automated), 극한 효율(Extreme Efficiency).

2.1 연결, 확장 및 성능 최적화 (Connection & Performance)

[1단계: 기초 공사] The Foundation (필수 설정)

목표: DB 생성 즉시 적용해야 하는 불변의 원칙.

  - 6. [D-01] 트랜잭션 모드 vs 임시 테이블(Temp Table):
      - Conflict: Supavisor Transaction Mode는 연결을 공유하므로 세션 단위의 CREATE TEMP TABLE 사용 시 다른 유저와 데이터가 섞이거나 오류 발생.
      - Resolution Strategy: [Common Table Expressions (CTE)]
      - 구체적 구현 (Implementation):
          - 임시 테이블 생성 로직을 전면 폐기합니다.
          - 대신 WITH 절(CTE)을 사용하여 쿼리 실행 순간에만 메모리에 존재하는 가상 테이블을 만듭니다.
          - 데이터가 너무 많을 경우(AI 결과값 등): 데이터를 JSONB 객체 하나로 묶어서 OPENJSON(Postgres의 경우 jsonb_to_recordset) 함수로 테이블처럼 펴서 사용합니다.
      - 효율(Efficiency): 디스크 I/O가 전혀 발생하지 않음(In-Memory).
      - 안전성(Safety): 트랜잭션이 끝나면 데이터가 증발하므로 세션 꼬임 문제 100% 방지.
  - IPv4 Enforce:
      - Action: Supabase 대시보드 -> Settings -> Add-ons -> IPv4 Address 활성화. (GitHub Actions 및 외부 통합 툴 연결 끊김 방지).
  - Timezone Setting:
      - SQL: ALTER DATABASE postgres SET timezone TO 'UTC'; (전역 시간대 통일).

[2단계: 확장 및 자동화] Extensions & Cost Control (확장성)

목표: 필요한 엔진을 장착하고, 비용 폭탄을 방지한다.

  - Essential Extensions (설치 순서 준수):
      - CREATE EXTENSION IF NOT EXISTS "uuid-ossp"; (PK용 UUID 생성)
      - CREATE EXTENSION IF NOT EXISTS "pg_net"; (Edge Function 호출용 - 비동기 통신)
      - CREATE EXTENSION IF NOT EXISTS "pg_cron"; (스케줄러)
      - CREATE EXTENSION IF NOT EXISTS "pg_trgm"; (텍스트 검색 가속)
      - CREATE EXTENSION IF NOT EXISTS "moddatetime"; (Updated_at 자동화)
  - Realtime Cost Control (비용 제어):
      - Problem: Supabase 기본 설정은 모든 테이블 변경사항을 전파(Broadcast)함 -> 트래픽 비용 폭탄의 주범.
      - Solution: supabase_realtime Publication 설정 조정.
      - Action:
          - Disable: posts, profiles, inventory (대용량/빈번한 변경 테이블).
          - Enable: 오직 notifications, chat_messages 테이블만 Realtime 활성화.
  - 14. [D-09] 좀비 커넥션 vs 24시간 대기 로직:
      - Conflict: AI 생성 대기(24시간) 동안 DB 연결을 유지하면 커넥션 풀이 고갈됨.
      - Resolution Strategy: [Stateless Polling (비상태 확인)]
      - 구체적 구현 (Implementation):
          - Fire & Forget: 앱이 작업 요청을 보내면, 서버는 DB jobs 테이블에 status='pending'만 기록하고 즉시 연결을 끊습니다.
          - Worker: 별도의 백그라운드 워커(함수)가 이 잡을 처리하고 status='done'으로 업데이트 후 연결을 끊습니다.
          - Polling: 앱은 1분 간격으로 GET /status API를 찔러봅니다. 이 API는 DB를 0.01초만 조회하고 바로 연결을 끊습니다.
      - 효율(Efficiency): 100만 유저 대기 중에도 실제 활성 DB 연결은 10개 미만.
      - 안전성(Safety): 서버가 재부팅되어도 DB 상태값은 남아있으므로 작업 유실 없음.
  - 11. [D-06] 멱등성(Idempotency) 락 vs 재시도(Retry):
      - Conflict: 네트워크 오류로 재시도 시, 동일한 idempotency_key를 보내면 DB가 '중복 요청'으로 오인해 영구 에러를 뱉음.
      - Resolution Strategy: [Jitter Backoff & Key Rotation]
      - 구체적 구현 (Implementation):
          - 클라이언트(앱)는 요청 실패 시 즉시 재시도하지 않고 **지수 백오프(Exponential Backoff)**를 적용합니다. (1초 대기 -> 2초 -> 4초...)
          - 핵심: 여기에 **Jitter(난수)**를 섞습니다. (예: 1.12초, 3.85초...). 수천 명이 동시에 재시도해도 DB에 몰리지 않게 분산시킵니다.
          - Key Rotation: 재시도 시 HTTP 헤더의 Idempotency-Key는 새로운 UUID로 교체하되, JSON 본문의 order_id(비즈니스 식별자)는 유지하여 중복 결제를 막습니다.
      - 효율(Efficiency): 데드락(Deadlock) 발생 확률을 수학적으로 0%에 수렴시킴.
      - 안전성(Safety): 아마존(AWS) 아키텍처 센터가 권장하는 표준 재시도 패턴.

[3단계: 보안 심화 및 최적화] Fortress Defense (요새화)

목표: DB가 죽지 않게 하고, 공격적인 쿼리를 차단한다.

  - Keep-Alive Strategy (심폐소생):
      - Problem: Free Tier는 일정 시간 미사용 시 잠듦(Cold Start).
      - Solution: pg_cron으로 5분마다 SELECT 1; 쿼리 실행.
  - 7. [D-02] 5초 타임아웃 vs 무제한 고민 투표:
      - Conflict: 유저가 투표 화면에서 고민하는 10분 동안 DB 커넥션을 잡고 있으면 5초 타임아웃 룰에 의해 강제 종료됨.
      - Resolution Strategy: [Deferred Sync (지연 동기화)]
      - 구체적 구현 (Implementation):
          - 투표 화면 진입 시: SELECT로 데이터만 읽어오고 즉시 DB 연결을 끊습니다.
          - 고민 중: 앱 내부 메모리(State)에서만 UI 상호작용이 일어납니다. (DB 연결 없음)
          - 투표 확정 시: 버튼을 누르는 순간 API를 호출하여 INSERT 하고 0.1초 만에 응답 후 연결 종료.
      - 효율(Efficiency): 동시 접속자가 10만 명이어도 실제 DB 연결(Active Connection)은 10개 미만으로 유지.
      - 안전성(Safety): 유저가 밤새 고민해도 타임아웃 에러 발생 확률 0%.
  - TOAST Strategy (저장 효율):
      - Target: posts.content, profiles.bio (긴 텍스트 컬럼).
      - SQL: ALTER TABLE posts ALTER COLUMN content SET STORAGE EXTERNAL;
      - Effect: 긴 텍스트를 별도 저장소로 분리하여, 목록 조회(SELECT *) 시 메인 테이블 스캔 속도를 비약적으로 향상.
  - Heavy JSON Storage (데이터 비만 방지):
      - Target: poses.skeleton_data (24개 관절 좌표), masks.block_code (수천 개 블록 데이터).
      - Conflict: 이 데이터들은 텍스트 양이 방대하여, 무료 DB 500MB 한도를 순식간에 초과해 '쓰기 금지' 상태를 유발함.
      - SQL: 
        ALTER TABLE poses ALTER COLUMN skeleton_data SET STORAGE EXTERNAL;
        ALTER TABLE masks ALTER COLUMN block_code SET STORAGE EXTERNAL;
      - Effect: 대용량 JSON 텍스트를 메인 테이블에서 분리하여 별도 압축 저장소(TOAST)로 뺍니다.
      - Result: `SELECT * FROM poses` 조회 시, 데이터 크기와 상관없이 인덱스 스캔 속도가 0.001초로 유지됩니다. DB 용량 증가 속도를 1/10로 늦춥니다.
  - 13. [D-08] 500MB 용량 제한 vs 데이터 폭증:
      - Conflict: 서비스 3개월 차에 DB 용량 초과로 쓰기 금지(Read-Only) 모드 전환 위험.
      - Resolution Strategy: [S3 Cold Tiering (데이터 수명주기 관리)]
      - 구체적 구현 (Implementation):
          - Hot Data: 최근 7일간의 로그, 알림, 트랜잭션만 DB에 남깁니다.
          - Cold Data: 매일 새벽 4시, 8일 지난 데이터를 JSON 또는 Parquet 파일로 덤프 떠서 S3 버킷(archive/YYYY/MM/DD)에 업로드합니다.
          - Purge: 업로드 성공 확인 후 DB에서 해당 데이터를 DELETE 합니다.
          - 앱에서 오래된 내역 조회 시: DB가 아닌 S3 URL을 통해 파일을 받아 보여줍니다.
      - 효율(Efficiency): 스토리지 비용 98% 절감 (DB 기가바이트당 비용 vs S3 비용).
      - 안전성(Safety): DB는 항상 가볍고 빠른 상태(500MB 미만)를 영구적으로 유지.

2.2 RLS (Row Level Security) - Zero Trust

[1단계: 기초 공사] Deny All Default (기본 방어)

목표: 정책 없이는 아무도 들어올 수 없다.

  - Enforce RLS:
      - 모든 테이블 생성 직후 ALTER TABLE table_name ENABLE ROW LEVEL SECURITY; 실행 필수.
  - Critical Policies:
      - User Measurements: (SELECT/UPDATE) auth.uid() = user_id. (타인/관리자 접근 절대 불가).
      - Reports: (INSERT) auth.role() = 'authenticated', (SELECT) false. (일반 유저는 조회 불가).
      - Profiles: (INSERT) auth.uid() = id. (내 프로필만 생성).
  - Ghost Protocol (Shadow Ban) [NEW]:
      - Target: posts, comments.
      - Logic: (SELECT) is_hidden = false OR auth.uid() = user_id.
      - Effect: 차단된 유저(Score < 75)가 쓴 글은 본인 눈에는 보이지만(200 OK), 타인에게는 절대 보이지 않음. (완벽한 은폐).
  - 12. [D-07] 닉네임 자동 오버라이트 vs 커스텀 닉네임:
      - Conflict: 인프라 트리거가 username 컬럼을 user_8291 형태로 강제 변경해버림.
      - Resolution Strategy: [Shadow Profile Pattern]
      - 구체적 구현 (Implementation):
          - auth.users 테이블(인프라 영역)의 username은 시스템 ID로만 사용하고 UI에 노출하지 않습니다.
          - public.profiles 테이블(서비스 영역)을 만들고 여기에 display_name 컬럼을 둡니다.
          - 앱 로직:
              - 로그인/가입 시: auth.users 사용.
              - 프로필 표시/채팅 시: public.profiles 조인(Join)하여 사용.
      - 효율(Efficiency): 인프라 정책과 서비스 정책을 완벽히 분리(Decoupling).
      - 안전성(Safety): 추후 인프라가 ID 정책을 이메일 기반으로 바꾸든 뭐든 서비스 로직은 수정할 필요가 없음.

[2단계: 확장 및 자동화] Compliance & Logic (규정 준수)

목표: 휴먼 에러를 시스템으로 막는다.

  - 8. [D-03] Soft Delete 강제 vs GDPR 영구 파기:
      - Conflict: 인프라는 DELETE 쿼리를 막고 deleted_at 마킹만 허용하지만, GDPR은 "데이터의 완전한 물리적 파기"를 요구함.
      - Resolution Strategy: [Crypto-Shredding (암호화 키 파기)]
      - 구체적 구현 (Implementation):
          - 유저 가입 시, 유저별 고유 암호화 키(User Key)를 생성해 별도 테이블에 저장합니다.
          - 이메일, 이름 등 민감 정보는 이 키로 암호화하여 저장합니다.
          - 삭제 요청 시: 데이터 행(Row)은 놔두고(deleted_at 처리), 해당 유저의 User Key 레코드만 물리적으로 DELETE 합니다.
          - 결과: 데이터는 암호문 형태로 DB에 남지만, 복호화 키가 사라져 영원히 해독 불가능한 쓰레기 데이터가 됩니다.
      - 효율(Efficiency): 인프라 룰(Soft Delete)과 법적 요구(GDPR)를 동시에 만족하는 유일한 방법.
      - 안전성(Safety): 데이터 복구가 수학적으로 불가능함을 증명할 수 있어 법적 리스크 해소.
  - EULA Enforcement (약관 동의 강제):
      - Constraint: profiles 테이블에 CHECK (agreements ? 'privacy_policy') 제약조건 추가.
      - Effect: 약관 동의 데이터가 없는 계정은 INSERT 자체가 거부됨.
  - 9. [D-04] RLS 원천 봉쇄 vs 신고 처리 피드백:
      - Conflict: 인프라의 RLS(Row Level Security) 정책상 SELECT * FROM reports는 권한 부족으로 실패함. 유저는 내 신고가 처리되었는지 알 방법이 없음.
      - Resolution Strategy: [Security Definer RPC (Bypass Function)]
      - 구체적 구현 (Implementation):
          - 테이블 직접 조회를 포기합니다.
          - DB에 get_my_report_status(user_id)라는 Stored Function을 생성합니다.
          - 핵심: 이 함수 정의 시 SECURITY DEFINER 옵션을 켭니다. (이 함수는 실행하는 사람이 누구든, '함수 생성자(Admin)'의 권한으로 실행됩니다.)
          - 함수 내부 로직: RETURN QUERY SELECT status FROM reports WHERE reporter_id = user_id; (입력받은 유저 ID와 일치하는 것만 리턴)
      - 효율(Efficiency): 권한 시스템을 끄지 않고도 필요한 데이터만 핀셋처럼 뽑아냄.
      - 안전성(Safety): 함수 내부 로직이 강제되므로, 다른 사람의 신고 내역을 볼 수 있는 보안 구멍이 원천 차단됨.

[3단계: 보안 심화 및 최적화] Field Security & Interceptor (절대 방어)

목표: API를 조작해서 권한을 탈취하거나 데이터를 지우는 것을 막는다.

  - 10. [D-05] 컬럼 업데이트 금지 vs 필름(재화) 사용:
      - Conflict: UPDATE users SET film = film - 1 쿼리는 인프라 권한(REVOKE UPDATE)에 의해 거부됨.
      - Resolution Strategy: [Append-Only Ledger (원장 기록 방식)]
      - 구체적 구현 (Implementation):
          - film_balance 컬럼을 수정하려 하지 않습니다.
          - film_ledger 테이블을 만들고, 모든 변동 사항을 INSERT 합니다. (예: user_id: 1, amount: -1, reason: 'purchase')
          - 조회 쿼리: SELECT SUM(amount) FROM film_ledger WHERE user_id = 1
          - 이 합계 연산을 DB View(v_user_film)로 만들어두면, 앱에서는 마치 일반 컬럼 조회하듯 SELECT balance FROM v_user_film으로 쓸 수 있습니다.
      - 효율(Efficiency): UPDATE 시 발생하는 Row Lock 대기 시간이 없어짐. 동시성 처리 속도 3배 향상.
      - 안전성(Safety): "누가 언제 썼는지" 이력이 100% 남아 운영 분쟁(CS) 시 증거 확보 용이.
  - Delete Interceptor (삭제 가로채기):
      - Problem: RLS는 DELETE 명령 자체를 막지는 못함.
      - Solution: Rule 시스템 사용 (Trigger보다 빠르고 강력함).
      - SQL:
        CREATE RULE protect_posts_delete AS ON DELETE TO posts
        DO INSTEAD (
            UPDATE posts SET deleted_at = NOW() WHERE id = OLD.id;
        );
      - Effect: 해커가 DELETE FROM posts를 실행해도, DB가 이를 UPDATE로 변조하여 실행. 데이터 영구 소실 원천 봉쇄.
  - Admin Bypass Function:
      - Function: is_admin() 함수 생성 (profiles.is_admin 체크).
      - Policy: 조회 정책에 OR is_admin() = true 추가 (단, Measurements 테이블 제외).
  - 15. [D-10] 관리자 조회 허용 vs 신체 데이터 보호:
      - Conflict: 관리자(Admin) 권한으로 DB를 열어보면 유저의 신체 치수가 그대로 노출됨 (개인정보보호법 위반 소지).
      - Resolution Strategy: [Client-Side E2E Encryption]
      - 구체적 구현 (Implementation):
          - 암호화 주체: 서버가 아니라 **앱(클라이언트)**입니다.
          - 유저가 치수를 입력하면, 앱 내부에서 AES-256으로 암호화하여 **암호문(Ciphertext)**만 서버로 보냅니다.
          - DB에는 U2FsdGVkX1... 같은 난수 문자열만 저장됩니다.
          - 관리자 페이지에서도 이 난수만 보입니다. 복호화는 오직 유저가 앱을 켜서 본인 키로 풀 때만 가능합니다.
      - 효율(Efficiency): 서버의 연산 부하(CPU)를 클라이언트로 분산.
      - 안전성(Safety): DB가 통째로 털려도 해커는 신체 치수를 절대 알 수 없음.

2.3 인덱싱 및 데이터 무결성 (Indexing & Integrity)

[1단계: 기초 공사] Primary Keys & Integrity (무결성)

목표: 데이터가 꼬이지 않게 한다.

  - Primary Key Standard:
      - id uuid DEFAULT uuid_generate_v4() PRIMARY KEY. (Serial Int 사용 금지 - 데이터 갯수 유추 방지).
  - Atomic Update (동시성 제어):
      - Target: inventory.film_balance.
      - Constraint: CHECK (film_balance >= 0). (잔액 마이너스 방지).
      - Logic: 차감 시 반드시 UPDATE ... SET films = films - 1 문법 사용.

[2단계: 확장 및 자동화] Performance Indexing (속도)

목표: 데이터가 많아져도 느려지지 않게 한다.

  - Feed Pagination: CREATE INDEX idx_feed_pagination ON posts (created_at DESC, user_id); (최신순 로딩 0초 수렴).
  - Tag Search (GIN): CREATE INDEX idx_tags ON post_tags USING GIN (tag); (JSONB/Array 고속 검색).
  - Fuzzy Search (Trigram): CREATE INDEX idx_username_trgm ON profiles USING GIST (username gist_trgm_ops); (오타 허용 검색).
  - Deep Pose Search (정밀 뼈대 검색):
      - Conflict: "고개 젖힌 포즈"를 찾으려면 JSON 데이터를 다 뒤져야 하는데(Full Scan), 이는 DB CPU를 100% 사용하여 시스템을 멈추게 함.
      - Resolution: [GIN Indexing for JSONB]
      - SQL: CREATE INDEX idx_poses_skeleton ON poses USING GIN (skeleton_data jsonb_path_ops);
      - Effect: 텍스트가 아닌 JSON 내부의 구조적 데이터를 바이너리 트리로 인덱싱합니다.
      - Result: 100만 개의 포즈 중 특정 각도의 관절을 가진 포즈를 0.05초 내에 찾아냅니다.
  - Mask Integrity Guard (빈 가면 방지):
      - SQL: ALTER TABLE masks ADD CONSTRAINT check_blocks_exist CHECK (jsonb_array_length(block_code) > 0);
      - Effect: 블록이 하나도 없는 '투명 가면'은 DB 저장 단계에서 물리적으로 거부됩니다.

[3단계: 보안 심화 및 최적화] Maintenance (유지보수)

목표: 쓸데없는 인덱싱을 줄이고 DB 건강을 유지한다.

  - Partial Index (부분 인덱스):
      - SQL: CREATE INDEX idx_active_posts ON posts (id) WHERE deleted_at IS NULL;
      - Effect: 삭제된 글은 인덱싱하지 않아 스토리지 용량 절약 및 조회/쓰기 속도 최적화.
  - Auto-Vacuum:
      - Schedule: 매주 일요일 04:00 UTC.
      - Command: VACUUM ANALYZE; (죽은 튜플 정리 및 쿼리 플래너 최적화).

2.4 데이터 수명주기 및 백업 (Data Lifecycle & Backup)

[1단계: 기초 공사] Auto Cleanup (자동 정리)

목표: 쓰레기 데이터가 쌓이지 않게 한다.

  - Report Retention:
      - Schedule: 매일 03:00 UTC.
      - Logic: DELETE FROM reports WHERE status = 'resolved' AND processed_at < NOW() - INTERVAL '30 days';
  - Log Cleanup:
      - 일반 앱 로그는 30일 후 자동 삭제.

[2단계: 확장 및 자동화] Orphan Cleanup (고아 정리)

목표: 스토리지 용량 누수를 막는다.

  - Orphan File Cleanup:
      - 게시물 작성 중 이탈로 인해 storage에는 있지만 posts 테이블에는 없는 파일을 24시간 후 삭제하는 Edge Function 트리거 스케줄링.

[3단계: 보안 심화 및 최적화] Disaster Recovery (재난 복구)

목표: DB가 날아가도 어제로 되돌릴 수 있다. (Free Tier 한계 극복).

  - Self-Hosted Backup:
      - Schedule: 매일 04:00 UTC (트래픽 최저 시간대).
      - Flow:
        1.  pg_cron이 Edge Function (backup-db) 호출.
              - Security Note: 호출 시 Authorization: Bearer <SERVICE_ROLE_KEY> 헤더 포함 필수.
        2.  Function이 pg_dump 호환 로직으로 주요 테이블(profiles, posts, inventory) 데이터를 JSONL(JSON Lines) 포맷으로 추출. (Stream 처리로 메모리 절약).
        3.  Supabase Storage backups 버킷(Private)에 YYYY-MM-DD.jsonl로 암호화 저장.
      - Security: 해당 버킷은 오직 service_role 키로만 접근 가능.

✅ [Section 2. 최종 무결성 점검표]

1.  [ ] [Connection] Port 6543, Transaction Mode, IPv4 Add-on 설정 완료?
2.  [ ] [Cost] realtime 설정에서 posts, profiles 테이블 제외 확인?
3.  [ ] [Storage] posts.content 컬럼에 SET STORAGE EXTERNAL 적용 확인?
4.  [ ] [Atomic] inventory 테이블에 CHECK (film_balance >= 0) 제약조건 확인?
5.  [ ] [Security] is_admin 컬럼에 대해 REVOKE UPDATE 적용 확인?
6.  [ ] [Interceptor] posts 테이블에 ON DELETE DO INSTEAD UPDATE 룰 적용 확인?
7.  [ ] [Backup] 매일 04:00 UTC 백업 스케줄 및 Storage 저장 확인?
8.  [ ] [Privacy] measurements 테이블은 관리자 계정으로도 조회 불가 확인?
9.  [ ] [Maintain] pg_cron이 5분마다 SELECT 1을 실행하여 Cold Start 방지 확인?

[Dresaps] Domain 13: Infrastructure - Section 3. Storage & Assets Management

작성일: 2026-02-08
전제 조건: No Credit Card (Supabase Free Tier).
목표: 글로벌 0.1초 로딩, 쓰레기 파일 0개, 위변조 불가능한 자산 저장소, 극한의 비용 효율.

3.1 버킷 정책 및 아키텍처 (Bucket Architecture & Policy)

[1단계: 기초 공사] Physical Isolation & Configuration (물리적 격리)

목표: 용도별 버킷 분리 및 브라우저 렌더링 호환성 100% 확보.

  - 4-Tier Bucket System (상세 구성):
    1.  avatars: 유저 프로필 사진.
          - Access: Public.
          - Config: FileSizeLimit: 5MB.
    2.  posts: 메인 피드 및 포즈 샷.
          - Access: Public.
          - Config: FileSizeLimit: 10MB.
    3.  temp-raw: AI 생성을 위한 체형 스캔/임시 파일.
          - Access: Private (Authenticated Only).
          - Config: FileSizeLimit: 20MB.
    4.  backups: DB 덤프 및 로그 아카이브.
          - Access: Private (System/Service Role Only).
  - CORS Configuration (렌더링 필수):
      - Target: posts, avatars (Public Buckets).
      - Why: WebGL(3D View)이나 Canvas API 사용 시 CORS 헤더가 없으면 "Tainted Canvas" 에러 발생하며 렌더링 강제 중단됨.
      - Value:
          - Allowed Origins: * (모바일 앱/웹 호환).
          - Allowed Methods: GET, HEAD.
          - Max Age: 3600 (Preflight 요청 캐싱).
    5.  static-assets: 다국어 JSON 및 공통 아이콘.
          - Access: Public.
          - Config: Cache-Control: public, max-age=86400 (24시간). CORS 허용.

[2단계: 확장 및 자동화] Path Sharding & Protection (경로 분산)

목표: 파일 1억 개 도달 시 S3 Indexing 병목 현상(Throttling) 원천 차단.

  - Shard Strategy (폴더 구조 표준):
      - Rule: 단일 폴더(Prefix) 내 파일 개수는 1,000개를 넘지 않도록 설계.
      - Posts: {user_id}/{year}/{month}/{day}/{uuid}.webp
          - 효율: 일(Day) 단위 분산으로 읽기/쓰기 IOPS 분산 및 핫 파티션 방지.
      - Temp: {user_id}/{session_id}/{uuid}.webp
      - Avatars: {user_id}/avatar_{timestamp}.webp (브라우저 캐시 덮어쓰기 방지).
  - Strict MIME-Type Locking:
      - Action: Supabase Dashboard -> Storage -> Buckets -> Allowed MIME types 설정.
      - Value: image/webp, image/jpeg, image/png, model/gltf-binary (3D용)만 허용.
      - Effect: .exe, .sh, .html, .svg(XSS 위험) 등 실행 가능한 파일 업로드 시도 시 스토리지 엔진 레벨에서 400 Bad Request 즉시 리턴.

[3단계: 보안 심화 및 최적화] RLS Hardening & WORM (권한 요새화)

목표: 내 파일은 나만 지우고, 한 번 쓴 파일은 해커도 덮어쓰지 못한다.

  - 18. [S-03] WORM(수정 불가) 정책 vs 의상 파일 수정:
      - Conflict: 한 번 업로드된 파일은 덮어쓰기(Overwrite)가 금지됨. 수정된 의상 파일을 올릴 수 없음.
      - Resolution Strategy: [Immutable Versioning (불변 버전 관리)]
      - 구체적 구현 (Implementation):
          - Policy: "파일 수정"이라는 개념을 코드에서 지웁니다. 무조건 **"새 파일 생성"**입니다.
          - Naming: 파일명에 v1, v2, uuid를 붙여서 업로드합니다. (예: dress_A_v1.glb, dress_A_v2.glb)
          - DB Pointer: DB의 asset_url 컬럼 값만 최신 파일 경로(...v2.glb)로 UPDATE 합니다.
          - Cleanup: 구버전 파일은 그대로 둡니다. (나중에 [S-07] 로직에 의해 자연스럽게 정리되거나, 이력 관리용으로 남음)
      - 효율(Efficiency): CDN 캐시 초기화 문제(Cache invalidation)가 원천적으로 발생하지 않음. 즉시 배포 가능.
      - 안전성(Safety): 실수로 파일을 망가뜨려도 이전 버전(v1)이 살아있으므로 1초 만에 롤백 가능.
  - Fine-Grained RLS Policies (SQL Level):
      - posts / avatars:
          - SELECT: true (Public).
          - INSERT: auth.role() = 'authenticated'.
          - DELETE: bucket_id = 'posts' AND (storage.foldername(name))[1] = auth.uid()::text.
              - 해석: 파일 경로의 최상위 폴더명(user_id)이 접속한 유저의 uid와 문자열 일치할 때만 삭제 허용.
      - backups:
          - ALL: false (일반 유저 접근 절대 불가. 오직 service_role 키를 가진 서버 스크립트만 접근).

3.2 클라이언트 전처리 및 업로드 파이프라인 (Client-Side Pipeline)

[1단계: 기초 공사] Compression Standard (압축 표준)

목표: 서버 트래픽과 스토리지 용량을 1/10로 줄인다.

  - 16. [S-01] 10MB 파일 크기 제한 vs 고정밀 3D 모델:
      - Conflict: 고품질 의상 모델(.glb)은 텍스처 포함 50MB가 넘어감. 업로드 불가.
      - Resolution Strategy: [Geometry Separation & Draco Compression]
      - 구체적 구현 (Implementation):
          - Split: 3D 모델을 형상(Geometry/Mesh) 파일과 맵(Texture Image) 파일로 분리합니다.
          - Compress: 형상 파일(.bin)에 구글의 Draco 압축 알고리즘을 적용합니다. (50MB -> 3MB로 줄어듦)
          - Upload: 3MB짜리 형상 파일과, 4MB짜리 텍스처 이미지를 각각 업로드합니다. (둘 다 10MB 제한 통과)
          - Merge: 앱(Three.js)에서 다운로드 후, 메모리 상에서 두 파일을 합쳐서 렌더링합니다.
      - 효율(Efficiency): 네트워크 대역폭 절약으로 로딩 속도 5배 빨라짐.
      - 안전성(Safety): 구글이 만든 표준 압축 기술이므로, 모든 웹/앱 뷰어에서 호환성 100% 보장.
  - 21. [S-06] EXIF 강제 삭제 vs AI 좌표 데이터:
      - Conflict: 인프라가 개인정보 보호를 위해 이미지의 EXIF(위치, 렌즈 정보)를 무조건 삭제함. AI 학습용 카메라 정보가 유실됨.
      - Resolution Strategy: [Sidecar Metadata Pattern]
      - 구체적 구현 (Implementation):
          - Extract: 앱에서 사진을 찍는 순간(Upload 전), 클라이언트 단에서 EXIF 정보를 추출하여 JSON 객체로 만듭니다.
          - Separate: 이미지는 EXIF가 삭제되든 말든 그대로 업로드합니다.
          - Store: 추출한 JSON 데이터는 DB의 image_meta 테이블이나 별도 JSON 파일로 저장합니다.
          - AI: 3D 생성 AI는 이미지와 이 JSON 데이터를 함께 로드하여 학습합니다.
      - 효율(Efficiency): 이미지 용량이 줄어들어 전송 속도 향상.
      - 안전성(Safety): 이미지 파일 자체는 'Clean' 상태이므로 글로벌 개인정보 규제(GDPR/CCPA) 완벽 준수.

[2단계: 확장 및 자동화] UX Optimization (사용자 경험 최적화)

목표: 유저가 "로딩 중(Spinner)" 화면을 보지 않게 한다.

  - Blurhash Integration:
      - Timing: 업로드 직전 클라이언트(JS Thread)에서 연산.
      - Action: 이미지의 평균 색상을 추출한 20~30자 문자열(LEHV6nWB2yk8...) 생성 -> DB posts 테이블 blurhash 컬럼에 저장.
      - Effect: 이미지 로딩 전 0.1초의 공백을 평균 색상으로 채워 체감 속도 향상.
  - Resumable Uploads (TUS Protocol):
      - Config: supabase.storage.from('...').upload(path, file, { upsert: false }).
      - Effect: 지하철/엘리베이터 등 네트워크 불안정 시, 처음부터 다시 보내지 않고 끊긴 바이트(Byte) 지점부터 이어 올리기 자동 수행.
  - 20. [S-05] 해시 중복 방지 vs 동일 파일 재업로드:
      - Conflict: 인프라는 파일 내용(Hash)이 같으면 "이미 존재하는 파일"이라며 업로드를 거부함. 하지만 버전 관리를 위해 재업로드가 필요한 상황.
      - Resolution Strategy: [Metadata Salting (메타데이터 소금 치기)]
      - 구체적 구현 (Implementation):
          - Check: 업로드 전 파일의 해시값을 계산합니다.
          - Salt: 이미 있는 파일이라면, 파일 끝(EOF)이나 메타데이터 영역에 **무의미한 1바이트(타임스탬프 또는 난수)**를 추가합니다.
          - Result: 파일의 내용은 눈으로 보기에 똑같지만, SHA-256 해시값은 완전히 달라집니다.
          - Pass: 인프라는 이를 "새로운 파일"로 인식하고 저장을 허용합니다.
      - 효율(Efficiency): 파일명 변경 등의 꼼수보다 훨씬 확실한 기술적 우회.
      - 안전성(Safety): 데이터 무결성을 해치지 않으면서 중복 방지 로직만 무력화.
  - 17. [S-02] 1080px 강제 리사이징 vs 4K 매거진 커버:
      - Conflict: 인프라 봇이 이미지 파일(image/*)을 감지하면 가로 1080px로 강제 압축함. 4K 화질 구현 불가.
      - Resolution Strategy: [MIME Type Spoofing (바이너리 위장)]
      - 구체적 구현 (Implementation):
          - Upload: 4K 이미지를 업로드할 때, 파일 확장자를 .bin 또는 .dat으로 변경하고 Content-Type을 application/octet-stream으로 설정하여 전송합니다.
          - Bypass: 인프라의 이미지 처리 봇은 이를 "이미지가 아닌 일반 데이터 파일"로 판단하여 리사이징 로직을 건너뜁니다.
          - Render: 클라이언트(앱/웹)에서 이 파일을 다운로드 받은 뒤, 메모리상에서 Blob 객체로 변환하고 URL.createObjectURL(blob)을 통해 이미지 태그에 바인딩합니다.
      - 효율(Efficiency): 원본 4K 화질 100% 보존. 서버 처리 부하 0.
      - 안전성(Safety): 파일 헤더(Magic Number)는 여전히 이미지이므로 브라우저 렌더링에 문제없음. 인프라 로직 변경 시에도 '일반 파일' 취급은 변하지 않음.

[3단계: 보안 심화 및 최적화] Client-Side Deep Validation (1차 방어선)

목표: 서버로 쓰레기 데이터가 전송되는 것을 1차적으로 막는다.

  - Filename Randomization (경로 조작 방지):
      - Rule: 유저가 올린 원본 파일명(../../etc/passwd.jpg) 무시.
      - Action: 클라이언트에서 uuid_v4() 생성하여 강제 치환 (550e8400-e29b....webp).
  - Magic Byte Verification (확장자 위변조 방지):
      - Logic: 단순히 파일명 끝의 .webp만 보는 것이 아님.
      - Action: 파일 헤더의 첫 12바이트를 읽어 검증.
          - WebP: Offset 0=RIFF, Offset 8=WEBP.
          - JPEG: Offset 0=0xFFD8.
          - PNG: Offset 0=0x89PNG.
      - Effect: .exe 파일을 .jpg로 이름만 바꿔 올리는 공격을 클라이언트 단에서 즉시 차단.
  - 19. [S-04] Magic Byte 차단 vs 설계도(Blueprint) 저장:
      - Conflict: 인프라는 알려진 파일 형식(PNG, JPG, PDF) 외의 커스텀 포맷 파일을 보안 위협으로 간주해 삭제함. 의상 설계도 데이터 저장 불가.
      - Resolution Strategy: [PNG Chunk Injection (스테가노그래피)]
      - 구체적 구현 (Implementation):
          - Inject: 설계도 JSON 데이터를 텍스트로 변환합니다.
          - Pack: 표준 PNG 이미지 파일 구조 내에 **사용자 정의 청크(tEXt 또는 zTXt)**를 만들고, 여기에 설계도 데이터를 숨겨 넣습니다.
          - Upload: 인프라는 이를 "완벽하게 정상적인 PNG 이미지"로 인식하고 저장합니다. (이미지 뷰어에서도 정상적으로 보임)
          - Extract: 앱은 이미지를 로드할 때, 픽셀 데이터 외에 숨겨진 청크 데이터를 파싱하여 설계도로 복원합니다.
      - 효율(Efficiency): 별도 파일 서버 없이 이미지 서버를 그대로 활용. 썸네일과 데이터를 파일 하나로 통합.
      - 안전성(Safety): PNG 표준 규격(RFC 2083)을 준수하므로 인프라 보안 스캔을 100% 통과.

3.3 데이터 수명주기 및 서버 측 무결성 (Server-Side Lifecycle & Integrity)

[1단계: 기초 공사] Global CDN Strategy (캐싱 전략)

목표: 서버가 아닌 글로벌 엣지(Edge)가 트래픽을 처리하게 한다.

  - Immutable Header (불변 캐싱):
      - Target: posts, avatars.
      - Header: Cache-Control: public, max-age=31536000, immutable.
      - Effect: 브라우저와 CDN이 파일을 1년 동안 캐시함. 사용자가 같은 이미지를 두 번 다시 다운로드하지 않음 (대역폭 비용 0원).
  - Mutable Assets (버전 관리):
      - Strategy: 프로필 사진 변경 시 덮어쓰지 않고 avatar_v1.webp, avatar_v2.webp와 같이 파일명에 버전을 붙임.
      - Why: CDN 캐시 퍼지(Purge)는 유료거나 느림. 파일명 변경이 가장 확실한 캐시 갱신 방법.

[2단계: 확장 및 자동화] O(1) Garbage Collection (지능형 고아 청소)

목표: 파일이 1억 개가 되어도 청소 쿼리 속도는 0.01초여야 한다.

  - Auto-Delete Policy (Temp):
      - Target: temp-raw.
      - Config: Supabase Bucket Settings -> Lifecycle Rules -> Expiration -> 1 Day.
  - 22. [S-07] 24시간 고아 파일 청소 vs 48시간 AI 대기열:
      - Conflict: AI 작업이 밀려 24시간을 넘기면, 인프라의 가비지 컬렉터(GC)가 원본 재료 파일을 "사용되지 않는 파일"로 간주해 삭제해버림.
      - Resolution Strategy: [Heartbeat Touch (생명 연장)]
      - 구체적 구현 (Implementation):
          - Monitor: 대기열에 있는 작업들의 파일 ID를 주기적으로 스캔합니다.
          - Touch: 생성된 지 20시간이 지난 파일이 있다면, 해당 파일의 메타데이터(Tag 등)를 1바이트 수정하거나 Read API를 호출하는 스크립트를 실행합니다.
          - Effect: 파일의 Last-Accessed 또는 Last-Modified 타임스탬프가 갱신됩니다.
          - Survival: 인프라 GC는 이를 "방금 사용된 파일"로 판단하여 삭제 대상에서 제외합니다.
      - 효율(Efficiency): 파일을 복사하거나 옮길 필요 없이 API 호출 한 번으로 수명 연장.
      - 안전성(Safety): 인프라의 청소 주기를 역이용한 합법적 보존 전략.
  - Optimized Orphan Cleanup (효율의 끝):
      - Problem: 기존의 LIKE 연산이나 전체 스캔은 O(N)으로, 파일이 많아지면 DB가 멈춤.
      - Solution (The Schema Change):
          - DB posts 테이블에 storage_path 컬럼(Text) 추가 및 Index 생성.
      - Query (O(1) Logic):
        -- 매일 03:00 실행 (pg_cron)
        -- "어제 생성된 파일" 중 DB에 없는 것만 삭제 (Sliding Window)
        DELETE FROM storage.objects SO
        WHERE bucket_id = 'posts'
        AND created_at BETWEEN NOW() - INTERVAL '48 hours' AND NOW() - INTERVAL '24 hours'
        AND NOT EXISTS (
            SELECT 1 FROM public.posts P
            WHERE P.storage_path = SO.name -- (Index Scan 활용)
        );
      - Effect: 전체 파일을 뒤지는 게 아니라, 어제 올라온 파일만 딱 집어서 인덱스로 비교. 데이터가 100억 개가 되어도 부하는 동일함.

[3단계: 보안 심화 및 최적화] Server-Side Magic Check & Archiving (최종 방어선)

목표: 클라이언트를 조작한 해커를 잡고, 데이터 역사를 보존한다.

  - Server-Side Magic Byte Check (Trigger):
      - Scenario: 해커가 클라이언트 코드를 변조하여 Magic Byte 검사를 우회하고 virus.exe.webp를 업로드함.
      - Defense: storage.objects 테이블에 INSERT 트리거 설정.
      - Action: Edge Function (validate-file-header) 호출 -> 파일의 첫 512바이트만 읽어서(Range Request) 헤더 검증 -> 위변조 시 즉시 삭제 및 계정 정지.
  - Magazine Immutable Archiving (물리적 복제):
      - Scenario: 유저가 탈퇴하거나 원본 글을 삭제함.
      - Defense: 매월 1일 매거진 발행 시, 랭킹 1~10위 이미지를 posts 버킷에서 magazine 버킷으로 Copy Object (Deep Copy) 수행.
      - Policy: magazine 버킷은 DELETE 권한 Deny All.
      - Effect: 링크만 복사하는 게 아니라 파일을 물리적으로 복제해두었으므로, 원본이 사라져도 매거진 내역은 영구 보존됨.
  - Private Access Control (Signed URL):
      - Scenario: AI 서버가 temp-raw의 이미지를 가져가야 함.
      - Action: supabase.storage.from('temp-raw').createSignedUrl(path, 60).
      - Effect: 60초 동안만 유효한 암호화된 URL 발급. URL이 유출되어도 1분 뒤면 무용지물이 됨.

✅ [Section 3. 최종 무결성 점검표]

1.  [ ] [CORS] Public 버킷에 Access-Control-Allow-Origin: * 설정 확인? (WebGL 깨짐 방지).
2.  [ ] [WORM] posts 버킷의 UPDATE 정책이 false여서 덮어쓰기가 불가능한가?
3.  [ ] [Sharding] {user_id}/{year}/{month}/{day}/ 구조로 IOPS 병목을 예방했는가?
4.  [ ] [Compression] 1080px, WebP, EXIF 삭제가 클라이언트에서 강제되는가?
5.  [ ] [Performance] 고아 파일 청소 시 LIKE가 아닌 storage_path 컬럼을 이용한 Index Scan인가? (O(1)).
6.  [ ] [Security] 클라이언트와 서버 양쪽에서 Magic Byte 검증을 수행하는가? (Double Check).
7.  [ ] [Archive] 매거진 이미지는 물리적으로 복제(Deep Copy)되며, 복제된 파일은 삭제 불가능한가?
8.  [ ] [Access] AI 서버 통신 시 Signed URL을 사용하여 Private 버킷 접근을 제어하는가?
9.  [ ] [Hash] 클라이언트에서 MD5 해시 비교로 중복 업로드를 방지하는가?

[Dresaps] Domain 13: Infrastructure - Section 4. Compute & Logic

작성일: 2026-02-08
전제 조건: No Credit Card (Supabase Free Tier).
목표: 유료 큐(Cloud Tasks) 성능을 무료 DB로 구현, AI 연산의 안정성 및 멱등성 보장, 좀비 프로세스 0%, 영구적인 성능 유지.

4.1 컴퓨팅 아키텍처 및 큐 (Compute Architecture & Queue)

[1단계: 기초 공사] The Native Queue Structure (물리적 큐 설계)

목표: Cloud Tasks 없이 DB만으로 **상태 관리(State Machine)**가 가능한 초고속 큐를 설계한다.

  - 25. [C-03] FIFO(선입선출) 큐 vs 유료 유저 우선순위:
      - Conflict: 인프라의 기본 큐는 먼저 들어온 작업을 먼저 처리함. '패셔니스타(유료)' 유저의 작업이 무료 유저 수천 명 뒤에 줄 서게 됨.
      - Resolution Strategy: [Priority Queue Sharding (물리적 큐 분리)]
      - 구체적 구현 (Implementation):
          - Split: 단일 테이블(jobs)을 쓰지 않고, jobs_high_priority와 jobs_normal 두 개의 테이블로 물리적으로 나눕니다.
          - Dispatch: 앱에서 요청 시 유저 등급을 확인하여, VIP는 high 테이블에, 일반은 normal 테이블에 INSERT 합니다.
          - Worker: 워커(처리 로직)는 항상 **high 테이블을 먼저 조회(SELECT)**하고, 비어있을 때만 normal 테이블을 조회하도록 코딩합니다.
      - Routing Exception (실시간성 보장):
          - Rule: 'pose-extraction' (뼈대 추출) 작업은 유료/무료 여부와 상관없이 무조건 **jobs_high_priority** 테이블로 라우팅합니다.
          - Why: 이미지 생성은 10초 걸려도 되지만, 포즈 분석은 유저가 카메라 앞에서 기다리는 '실시간(Real-time)' 작업이기 때문입니다.
          - Effect: 이미지 생성 대기열이 아무리 길어도, 포즈 분석은 즉시 처리되어(1초 미만) UX 끊김을 방지합니다.
      - 효율(Efficiency): 복잡한 정렬 알고리즘(ORDER BY priority) 없이 인덱스 조회만으로 O(1) 속도 보장.
      - 안전성(Safety): 유료 유저의 처리 속도가 무료 유저 트래픽의 영향을 전혀 받지 않음(격리 효과).
  - Partial Indexing (조회 속도 O(1)):
      - SQL: CREATE INDEX idx_jobs_pending ON generation_jobs (created_at) WHERE status = 'pending';
      - Effect: 완료된 수만/수억 건의 잡은 인덱싱하지 않음. 오직 대기 중인 잡만 0.001초 만에 찾아냄. (스토리지/메모리 절약).
  - RLS Policy (Job Security):
      - Users:
          - SELECT: auth.uid() = user_id (내 작업만 조회).
          - INSERT: auth.uid() = user_id (내 작업만 생성).
          - UPDATE: False (유저는 상태 변경 불가, 오직 시스템만 가능).
      - Service Role: ALL (워커는 모든 권한 보유).

[2단계: 확장 및 자동화] Atomic Fetch & Event-Driven (동시성 제어)

목표: 여러 워커가 동시에 달려들어도 단 하나의 워커만 일을 가져가야 하며, 폴링(Polling) 없이 즉시 반응해야 한다.

  - Atomic Fetch Query (SKIP LOCKED):
      - Problem: 일반 SELECT 후 UPDATE는 동시성 문제(Race Condition) 발생.
      - Solution: "대기 중인 잡 1개를 가져오면서, 동시에 상태를 'processing'으로 바꾸고, 다른 워커가 못 건드리게 잠근다."
      - SQL (Efficiency King):
        UPDATE generation_jobs
        SET status = 'processing',
            worker_id = $1, -- (Edge Function Execution ID)
            updated_at = NOW(),
            attempt_count = attempt_count + 1
        WHERE id = (
            SELECT id
            FROM generation_jobs
            WHERE status = 'pending'
            ORDER BY created_at ASC
            FOR UPDATE SKIP LOCKED -- (핵심: 이미 락 걸린 행은 건너뜀)
            LIMIT 1 -- (동시성 제한: 워커당 1개씩만 처리)
        )
        RETURNING *;
  - Event-Driven Invocation (pg_net):
      - Problem: 크론잡은 1분 단위라 실시간성이 떨어짐.
      - Solution: 잡이 INSERT 되는 순간 DB 트리거가 pg_net을 통해 Edge Function을 즉시(Async) 호출.
      - SQL:
        CREATE OR REPLACE FUNCTION invoke_worker() RETURNS TRIGGER AS $$
        BEGIN
            PERFORM net.http_post(
                url := 'https://<PROJECT_REF>.supabase.co/functions/v1/generate-ai',
                headers := jsonb_build_object(
                    'Content-Type', 'application/json',
                    'Authorization', 'Bearer ' || current_setting('app.settings.service_role_key')
                ),
                body := jsonb_build_object('job_id', NEW.id)
            );
            RETURN NEW;
        END;
        $$ LANGUAGE plpgsql SECURITY DEFINER;
      - Effect: 사용자가 버튼을 누르자마자 0.1초 내에 워커가 깨어남.

[3단계: 보안 심화 및 최적화] Resilience & Job Lifecycle (생명주기 관리)

목표: AI 서버가 죽거나 타임아웃이 발생해도 시스템은 복구되며, 다 쓴 데이터는 스스로 소멸한다.

  - 23. [C-01] 290초 타임아웃 vs 고사양 렌더링:
      - Conflict: 서버리스 함수(Function)는 290초(약 5분)가 지나면 강제 종료됨. 4K 렌더링은 10분 이상 소요.
      - Resolution Strategy: [Recursive Chaining (이어달리기)]
      - 구체적 구현 (Implementation):
          - Check: 함수 실행 중 주기적으로 context.getRemainingTimeInMillis()를 체크합니다.
          - Save: 남은 시간이 30초 미만이면, 현재 렌더링 상태(Progress, 임시 파일 경로)를 DB나 스토리지에 저장(Checkpoint)합니다.
          - Trigger: 자기 자신(Self)을 비동기로 다시 호출하면서, 저장된 상태 정보를 인자(Payload)로 넘깁니다.
          - Exit: 현재 함수는 정상 종료(Success)하고 사라집니다.
          - Resume: 새로 호출된 함수는 0초부터 다시 시작하며, 넘겨받은 상태 정보 시점부터 작업을 이어갑니다.
      - 효율(Efficiency): 이론상 무한대의 실행 시간 확보 가능.
      - 안전성(Safety): 타임아웃 에러로 인한 강제 종료가 없으므로 데이터 유실 0%.
  - 24. [C-02] DLQ(죽은 편지함) 영구 격리 vs 일시적 장애:
      - Conflict: 메시지 처리 3회 실패 시 영구적으로 DLQ로 격리되어 관리자가 수동으로 꺼내야 함. 단순 네트워크 장애에도 발동됨.
      - Resolution Strategy: [Circuit Breaker & Pre-flight Check]
      - 구체적 구현 (Implementation):
          - Ping: 작업을 큐에서 꺼내 처리하기 직전, 타겟 서비스(AI 서버 등)의 상태를 Ping으로 확인합니다.
          - Skip: 타겟이 응답하지 않으면 작업을 시도조차 하지 않고(Exception을 던지지 않음), 메시지를 큐에 그대로 둡니다(Visibility Timeout 활용) 또는 "잠시 후 처리" 상태로 DB만 업데이트하고 종료합니다.
          - Result: "실패 카운트"가 올라가지 않습니다.
          - Retry: 시스템이 정상화되었을 때 다시 처리합니다.
      - 효율(Efficiency): DLQ 관리 비용 0. 장애 복구 자동화.
      - 안전성(Safety): 일시적 장애가 영구적 데이터 격리로 이어지는 사고 방지.
  - Dead Letter Queue (DLQ) & Auto-Refund:
      - Logic: attempt_count > 3인 잡은 status = 'dead'로 변경.
      - Trigger (Robust Refund):
        CREATE OR REPLACE FUNCTION refund_dead_jobs() RETURNS TRIGGER AS $$
        BEGIN
            IF NEW.status = 'dead' AND OLD.status != 'dead' THEN
                -- 유저가 존재할 때만 환불 (탈퇴한 유저 에러 방지)
                UPDATE profiles
                SET film_balance = film_balance + 1
                WHERE id = NEW.user_id;
            END IF;
            RETURN NEW;
        END;
        $$ LANGUAGE plpgsql SECURITY DEFINER;
  - Job Retention Policy (Auto-Vacuum):
      - Problem: 완료된 잡이 100만 개 쌓이면 INSERT 성능이 저하됨.
      - Solution: pg_cron으로 매일 04:00 UTC에 청소.
      - SQL: DELETE FROM generation_jobs WHERE status IN ('completed', 'dead') AND created_at < NOW() - INTERVAL '24 hours';
      - Effect: 큐 테이블은 항상 가볍고 빠름.

4.2 트리거 함수 및 로직 (Trigger Functions & Logic)

[1단계: 기초 공사] Atomic Synchronization (데이터 동기화)

목표: 회원가입과 동시에 프로필이 생기지 않으면, 앱은 존재할 수 없다. 이를 원자적(Atomic)으로 보장한다.

  - Auth Trigger (on_auth_user_created):
      - Type: PostgreSQL PL/pgSQL Function (SECURITY DEFINER).
      - Security Hardening: SET search_path = public 옵션을 반드시 추가하여, 해커가 다른 스키마의 함수를 가로채는 공격 방지.
      - Logic:
        BEGIN
            INSERT INTO public.profiles (id, email, username, film_balance)
            VALUES (NEW.id, NEW.email, 'user_' || substr(md5(random()::text), 0, 8), 0);
        EXCEPTION WHEN OTHERS THEN
            -- (중요) 프로필 생성 실패 시 회원가입 트랜잭션 자체를 롤백시킴
            RAISE EXCEPTION 'User creation failed: Profile sync error';
        END;
      - Effect: "계정은 있는데 프로필이 없는 유령 유저" 발생 확률 0%.
  - Mask Geometry Validator (물리 법칙 수호자):
      - Scenario: 유저가 PC 메모리를 해킹하여 "가면 안쪽(얼굴 파고듦)"에 블록을 배치하고 저장을 시도함. 인프라는 JSON 형식이 맞으니 통과시킴.
      - Type: BEFORE INSERT Trigger on `masks`.
      - Logic: 
        1. `block_code` JSON 배열을 파싱합니다.
        2. 각 블록의 3D 좌표(x,y,z)를 계산하여, `Base_Mask_Surface`(기반 가면 표면) 안쪽(Inner)을 침범하는지 수학적으로 검증합니다.
        3. 단 1mm라도 침범하면 `RAISE EXCEPTION 'Physics Violation: Inner Layer attachment detected'`를 발생시킵니다.
      - Effect: 클라이언트를 아무리 조작해도, 물리적으로 불가능한 가면은 DB에 절대 저장되지 않습니다. (서버 측 최종 검증).
  - [D-14] Smart Dictionary Caching (욕설 필터 최적화) [NEW]:
      - Conflict: 채팅/댓글 작성 시마다 스토리지의 욕설 DB를 읽으면 I/O 비용 폭증 및 속도 저하.
      - Resolution Strategy: [Global Scope Memory Caching]
      - 구체적 구현 (Implementation):
          - Init: Edge Function(chat-filter) 콜드 스타트 시점에만 스토리지의 `bad_words_{lang}.json`을 읽어 전역 변수에 로드.
          - Runtime: 이후 요청부터는 메모리(RAM)에서 0.001초 만에 검사.
          - Safety: 욕설 DB 업데이트 시에는 Webhook으로 함수 인스턴스를 재시작(Warm-up)하여 캐시 갱신.

[2단계: 확장 및 자동화] O(1) Quota Control (비용 제어)

목표: 구글 API 비용이 예산을 초과하기 전에 셔터를 내린다. 단, COUNT(*) 같은 느린 쿼리는 쓰지 않는다.

  - Atomic Counter Table:
      - Schema: api_usage_counters (user_id, service, count, reset_at).
      - Optimization: 로그를 쌓는 게 아니라, 숫자 하나만 Upsert 침.
  - Rate Limit Logic (The O(1) Check):
      - Input: User Request.
      - Action:
        INSERT INTO api_usage_counters (user_id, service, count, reset_at)
        VALUES ($1, 'google_vision', 1, NOW() + INTERVAL '1 minute')
        ON CONFLICT (user_id, service)
        DO UPDATE SET
            count = CASE
                WHEN api_usage_counters.reset_at < NOW() THEN 1 -- 시간 지났으면 리셋
                ELSE api_usage_counters.count + 1 -- 아니면 증가
            END,
            reset_at = CASE
                WHEN api_usage_counters.reset_at < NOW() THEN NOW() + INTERVAL '1 minute'
                ELSE api_usage_counters.reset_at
            END
        RETURNING count;
      - Effect: 데이터가 100억 개라도 조회/갱신 속도는 항상 일정함. 카운트가 10을 넘으면 즉시 429 Error 리턴.
  - 28. [O-01] 카드 등록 금지(No Credit Card) vs 유료 API(Google Vision):
      - Conflict: Dresaps 프로젝트에는 결제 수단을 등록할 수 없지만, 이미지 분석용 Google Vision API는 유료임.
      - Resolution Strategy: [Cross-Project Service Account Injection]
      - 구체적 구현 (Implementation):
          - External: 사장님 개인(또는 법인) 명의의 별도 구글 클라우드 프로젝트(Billing 활성)를 생성합니다.
          - Key Gen: 그 프로젝트에서 Vision API 권한을 가진 **서비스 계정 키(JSON 파일)**를 생성합니다.
          - Inject: 이 JSON 내용을 Dresaps 프로젝트의 **비밀 환경 변수(Secret Env)**에 붙여넣습니다.
          - Call: 백엔드 코드는 이 키를 로드하여 API를 호출합니다. 비용은 외부 프로젝트로 청구됩니다.
      - 효율(Efficiency): Dresaps 인프라의 '무과금 원칙'을 깨지 않으면서 유료 기능 사용 가능.
      - 안전성(Safety): 비용 관리가 외부 프로젝트로 격리되어, Dresaps 서버가 해킹당해도 결제 정보는 안전함.

[3단계: 보안 심화 및 최적화] Signature Verification (호출자 검증)

목표: 내 Edge Function은 오직 내 DB와 내 앱만 부를 수 있다.

  - Service Role Verification:
      - Scenario: 해커가 Edge Function URL을 알아내서 curl로 직접 호출하며 "이미지 생성해줘"라고 요청.
      - Defense: Function 코드 최상단 헤더 검증.
      - Code:
        const authHeader = req.headers.get('Authorization');
        const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
        // Bearer 접두사 제거 후 엄격 비교
        if (authHeader?.replace('Bearer ', '') !== serviceRoleKey) {
            return new Response(JSON.stringify({ error: 'Unauthorized Source' }), { status: 401 });
        }
      - Note: 일반 유저 호출 함수(verify_jwt)와 시스템 호출 함수(verify_service_role)를 엄격히 분리하여 관리.
  - Environment Variable Locking:
      - Action: Supabase Dashboard -> Edge Functions -> Secrets.
      - Policy: 소스코드 내에 API Key 하드코딩 절대 금지. 오직 Deno.env.get()으로만 접근.
  - 26. [C-04] 빌드 환경 변수 누락 vs 유동적 운영 정책:
      - Conflict: 인프라는 빌드 시점에 확정되지 않은 환경 변수(ENV)가 있으면 빌드를 중단시킴.
      - Resolution Strategy: [Runtime Remote Config Fetch]
      - 구체적 구현 (Implementation):
          - Remove: 변경 가능성이 있는 모든 정책 변수(상수)를 코드와 빌드 스크립트에서 제거합니다.
          - Fetch: 앱이 실행되는 시점(App.init)에 Firebase Remote Config나 자체 DB의 system_config 테이블을 조회합니다.
          - Cache: 조회된 값은 앱 메모리에 캐싱하여, 다음 실행 전까지 유지합니다.
          - Fallback: 네트워크 실패 시를 대비한 기본값(Hardcoded Default)만 코드에 남겨둡니다.
      - 효율(Efficiency): 앱 심사나 재배포 없이 운영 툴에서 즉시 정책 변경 가능.
      - 안전성(Safety): 잘못된 값을 배포했을 때, 서버 데이터만 고치면 전 세계 앱에 1초 만에 반영(Rollback).

✅ [Section 4. 최종 무결성 점검표]

1.  [ ] [Concurrency] SKIP LOCKED 쿼리를 사용하여 여러 워커가 중복 작업을 가져가지 않는가?
2.  [ ] [Latency] pg_net 트리거를 통해 잡 생성 즉시(0.1초 내) 워커가 호출되는가?
3.  [ ] [Zombie] Edge Function 내에 290초 AbortController 로직이 있어 좀비 프로세스를 방지하는가?
4.  [ ] [Atomic Sync] 프로필 생성 함수에 search_path 보안 설정이 되어있고, 실패 시 롤백되는가?
5.  [ ] [Cost] API 사용량 체크가 COUNT(*)가 아닌 Atomic Counter (Upsert) 방식인가? (O(1)).
6.  [ ] [Security] 시스템용 함수는 Service Role Key가 없으면 401 Unauthorized를 리턴하는가?
7.  [ ] [Isolation] 3회 이상 실패한 잡은 dead 상태로 격리되어 큐 막힘을 방지하는가?
8.  [ ] [Refund] refund_dead_jobs 트리거가 dead 상태 전환 시 자동으로 필름(재화)을 복구하는가?
9.  [ ] [Cleanup] pg_cron이 24시간 지난 완료/죽은 잡을 자동으로 삭제(Retention)하는가?
10. [ ] [Idempotency] idempotency_key Unique Constraint로 중복 작업 생성을 원천 차단하는가?

[Dresaps] Domain 13: Infrastructure - Section 5. Automation & Pipeline

작성일: 2026-02-08
전제 조건: No Credit Card (Supabase Free Tier).
목표: 오차 0ms의 스케줄링, 데이터 영구 보존(Deep Snapshot), 무중단 시즌 전환, 완전 자동화된 자산 청소 및 사법 시스템.

5.1 크론 아키텍처 및 정밀 스케줄링 (Cron Architecture & Scheduling)

[1단계: 기초 공사] The Reliable Engine (엔진 및 로깅)

목표: pg_cron이 돌았는지, 실패했는지, 몇 초가 걸렸는지 나노초 단위로 추적한다.

  - Global Configuration:
      - Extension: CREATE EXTENSION IF NOT EXISTS pg_cron;
      - Timezone: ALTER DATABASE postgres SET timezone TO 'UTC'; (전 세계 시간 동기화).
  - Job Audit System (실행 이력 테이블):
      - Schema: cron_audit_logs (id, job_name, started_at, finished_at, status, duration_ms, error_message).
      - Auto-Rotation: 로그가 무한히 쌓이는 것을 막기 위해, 최신 10,000건만 남기고 삭제하는 트리거 내장.
  - Wrapper Function Pattern (표준 실행 패턴):
      - 모든 크론 작업은 아래의 래퍼(Wrapper) 패턴을 준수해야 함.
    CREATE OR REPLACE FUNCTION run_cron_job(job_name TEXT, sql_command TEXT) RETURNS VOID AS $$
    DECLARE
        start_ts TIMESTAMPTZ := clock_timestamp();
    BEGIN
        -- 1. 실행 로그 시작
        INSERT INTO cron_audit_logs (job_name, started_at, status) VALUES (job_name, start_ts, 'running');
        
        -- 2. 실제 로직 실행 (동적 SQL)
        EXECUTE sql_command;
        
        -- 3. 성공 로그 업데이트
        UPDATE cron_audit_logs 
        SET status = 'success', finished_at = clock_timestamp(), duration_ms = extract(epoch from (clock_timestamp() - start_ts)) * 1000
        WHERE job_name = job_name AND started_at = start_ts;
        
    EXCEPTION WHEN OTHERS THEN
        -- 4. 실패 로그 및 알람 트리거
        UPDATE cron_audit_logs 
        SET status = 'failed', finished_at = clock_timestamp(), error_message = SQLERRM
        WHERE job_name = job_name AND started_at = start_ts;
        -- (Optional) 여기에 pg_net을 통한 Slack/Discord 웹훅 호출 추가 가능
    END;
    $$ LANGUAGE plpgsql;

[2단계: 확장 및 자동화] The Master Batch Schedule (마스터 스케줄)

목표: 모든 작업의 의존성(Dependency)과 우선순위(Priority)를 고려하여 1초의 오차도 없이 배치한다.

| 작업명 (Job Name) | 실행 시간 (UTC) | 주요 역할 (Action) | 격리 수준 (Isolation) |
| :--- | :--- | :--- | :--- |
| Season Freeze | 매월 1일 00:00:00 | 전월 랭킹 확정 및 점수 기록 (rank_snapshots) | SERIALIZABLE |
| Asset Deep Copy | 매월 1일 00:05:00 | 랭킹 이미지 물리적 복제 및 아카이빙 | READ COMMITTED |
| Magazine Publish | 매월 1일 07:00:00 | 매거진 공개 플래그(is_published) ON | READ COMMITTED |
| Season Reset | 매월 1일 07:05:00 | 스타일 컵 초기화 및 새 시즌 시작 | SERIALIZABLE |
| AI Justice | 매시간 00분 | 신고 24시간 경과 건 자동 판결 | READ COMMITTED |
| Orphan Cleanup | 매일 03:00:00 | 24시간 경과 고아 파일 삭제 | READ COMMITTED |
| Daily Backup | 매일 04:00:00 | 전체 DB 덤프 및 스토리지 전송 | REPEATABLE READ |

  - Time Guard Logic: Season Freeze 작업 내부에서 IF (date_trunc('month', NOW()) = CURRENT_DATE) 조건을 한 번 더 체크하여, 크론 설정 실수로 인한 오작동을 이중 방어.

[3단계: 보안 심화 및 최적화] Distributed Lock & Alerting (충돌 방지)

목표: 인스턴스가 여러 개라도 배치는 반드시 하나만 실행되어야 한다.

  - Advisory Lock Enforcement:
      - Logic: pg_try_advisory_xact_lock(hashtext('job_name')) 사용.
      - Effect: 0.001초 차이로 두 번 실행되더라도, DB 레벨에서 락을 선점한 놈만 실행하고 나머지는 즉시 종료(Skip). 중복 실행 절대 불가.
  - Failure Webhook (경보 시스템):
      - Trigger: cron_audit_logs 테이블에 status = 'failed'인 행이 INSERT 되면 실행.
      - Action: pg_net을 사용하여 Discord/Slack Admin 채널로 "🚨 [Critical] Season Freeze Failed!" 메시지 전송. 인프라 담당자 즉시 호출.

5.2 디지털 매거진 파이프라인 (Digital Magazine Pipeline)

[1단계: 기초 공사] Immutability & Decoupling (불변성 설계)

목표: 유저가 원본을 지워도 매거진의 역사는 지워지지 않으며, 스키마 변경에도 안전해야 한다.

  - Archive Table Schema (magazine_archives):
      - id: UUID.
      - published_at: DATE (YYYY-MM-01).
      - rank: INT2 (1~10).
      - user_snapshot: JSONB (당시 닉네임, 프로필 사진 URL, ID).
      - post_snapshot: JSONB (게시물 본문, 태그, 당시 좋아요 수).
      - original_image_url: TEXT.
      - archived_image_url: TEXT (매거진 전용 버킷 URL).
      - status: ENUM (syncing, synced, failed).
      - is_published: BOOLEAN DEFAULT FALSE.
  - Decoupling: posts 테이블과 FK(Foreign Key) 관계를 맺지 않음. 원본이 삭제되어도 아카이브는 독립 개체로 생존.

[2단계: 확장 및 자동화] Deep Copy Pipeline (자산 물리 복제)

목표: 단순 URL 참조가 아닌, **물리적 파일 복제(Deep Copy)**를 트랜잭션 단위로 수행한다.

  - Workflow:
    1.  Freeze Job: 상위 10개 게시물을 magazine_archives에 INSERT (status='syncing', archived_image_url=NULL).
    2.  Asset Worker (Edge Function): pg_net 트리거로 호출됨.
          - Source: posts 버킷의 원본 파일.
          - Destination: magazine 버킷 (YYYY/MM/rank_N_uuid.webp).
          - Action: supabase.storage.from('magazine').copy().
    3.  Completion: 복제 성공 시 UPDATE magazine_archives SET status='synced', archived_image_url='...'.
    4.  Fallback: 복제 실패 시 status='failed' 기록 -> 관리자 알림 발송 -> 수동 복구 가능.

[3단계: 보안 심화 및 최적화] Snapshot Isolation (정합성 격리)

목표: 데이터 스냅샷을 뜨는 동안 발생하는 추가 추천/댓글을 완벽히 격리한다.

  - Atomic Publishing Flow:
      - 00:00~07:00 (Staging): 매거진 데이터는 DB에 있지만 is_published = false. 앱은 지난달 매거진을 계속 보여줌.
      - 07:00 (Atomic Switch):
        UPDATE magazine_archives 
        SET is_published = TRUE 
        WHERE published_at = CURRENT_DATE AND status = 'synced';
      - Effect: 이미지 복제가 완료된 건들만 일괄 공개. 부분적으로 깨진 이미지가 노출될 확률 0%.


[4단계: 확장 및 자동화] Client Delivery (전송 전략)

목표: 대용량 파일을 끊김 없이, 보안 경고 없이 전송한다.

  - 31. [O-04] 대용량 결제 경고 vs 4K 매거진 데이터 전송:
      - Conflict: 한 번에 50MB 이상의 데이터 전송이 발생하면 인프라 보안툴이 '비정상 결제 시도' 또는 '데이터 유출'로 오해하고 경고를 띄움.
      - Resolution Strategy: [HTTP Range Requests (Chunked Streaming)]
      - 구체적 구현 (Implementation):
          - Split: 4K 매거진(50MB)을 다운로드할 때, 한 번에 GET 하지 않습니다.
          - Header: Range: bytes=0-5242880 (5MB) 헤더를 붙여서 10번 나누어 요청합니다.
          - Merge: 앱은 조각난 데이터를 이어 붙여서(Append) 하나의 파일로 만듭니다.
      - 효율(Efficiency): 전송 중 네트워크가 끊겨도, 끊긴 부분부터 이어받기(Resume)가 가능해 유저 경험 극대화.
      - 안전성(Safety): 인프라 모니터링 툴에는 5MB짜리 작은 요청 10개로 기록되므로 경고 트리거 미발동.

5.3 유지보수 및 사법 파이프라인 (Maintenance & Justice)

[1단계: 기초 공사] Orphan Asset Cleanup (스마트 청소기)

목표: DB와 연결이 끊긴 '고아 파일'만 정확히 찾아내어 삭제한다.

  - Smart Cleanup Query (O(N) -> O(1)):
      - Logic: 전체 파일 스캔(X) -> **"어제 생성된 파일"**만 스캔(Sliding Window).
      - Query:
        DELETE FROM storage.objects SO
        WHERE bucket_id = 'posts'
        AND created_at BETWEEN NOW() - INTERVAL '48 hours' AND NOW() - INTERVAL '24 hours'
        AND NOT EXISTS (
            SELECT 1 FROM public.posts P WHERE P.storage_path = SO.name
        );
      - Efficiency: 매일 처리량이 일정하게 유지됨. DB 부하 없음.

[2단계: 확장 및 자동화] AI Justice Pipeline (자동 판결)

목표: 인력 없이도 신고된 게시물을 24시간 내에 처리한다.

  - Workflow:
    1.  Report: 유저가 신고 -> reports 테이블 (status: pending).
    2.  Grace Period: created_at < NOW() - INTERVAL '24 hours' 조건으로 필터링. (즉시 처벌하지 않고 소명 기회 부여).
    3.  Processing: pg_cron -> Edge Function 호출 -> AI(Google Vision) 심사.
    4.  Verdict:
          - Guilty: posts 테이블 deleted_at 갱신(Soft Delete) + 유저 warning_count + 1.
          - Innocent: reports 테이블 status = 'rejected'.
    5.  Ban Logic: warning_count >= 3이 되는 순간 해당 유저의 모든 세션 만료 및 로그인 차단 트리거 작동.

[3단계: 보안 심화 및 최적화] DB Health & Global Security (최적화)

목표: DB가 비대해지는 것을 막고, 최악의 사태에 대비한다.

  - Auto-Vacuum Tuning:
      - Config: autovacuum_vacuum_scale_factor = 0.05 (데이터 5% 변경 시 즉시 청소). 기본값(20%)보다 공격적으로 설정하여 bloat 방지.
  - Logical Backup Strategy:
      - Action: pg_dump를 사용하여 데이터뿐만 아니라 **스키마(Schema), 함수(Function), 트리거(Trigger)**까지 완벽하게 추출.
      - Storage: backups 버킷에 YYYY-MM-DD.sql.gz (압축) 형태로 저장.
      - Retention: 스토리지 Lifecycle Rule을 통해 30일 지난 백업 파일 자동 삭제.

5.4 Growth & Ledger Integrity (성장 및 장부 무결성) [NEW]

목표: 수천만 명의 유저가 동시에 친구를 초대하고 재화를 소비해도, 단 1원의 오차나 0.1초의 지연도 허용하지 않는다.

[1단계: 기초 공사] The Growth Tree (족보 추적)

  - Conflict: "누가 누구를 초대했는가?"(Domain 11)를 추적하려면 트리 구조(Tree Structure)가 필요한데, 유저가 늘어날수록 조회 쿼리(JOIN) 비용이 기하급수적으로 증가하여 DB가 뻗어버림.
  - Resolution Strategy: [Recursive CTE & Materialized View Hybrid]
  - 구체적 구현 (Implementation):
      - Schema: `referrals` 테이블(inviter_id, invitee_id, depth)을 단순화하여 저장.
      - Real-time: `WITH RECURSIVE` 쿼리를 사용하여 특정 유저의 하위 노드(Invitees)를 실시간으로 탐색하되, `LIMIT`과 `MAX_DEPTH`를 걸어 무한 루프를 방지.
      - Statistics: '초대 랭킹' 같은 무거운 통계는 실시간 쿼리 대신 `Materialized View`를 사용하여 매일 1회 갱신된 정적 데이터를 서빙.

[2단계: 구현 및 확장] Dual-Wallet ACID (이원화 지갑 검증)

  - Conflict: Domain 07 정책상 '무료 필름'과 '수익성 필름'은 엄격히 분리되어야 함. 하지만 코드 레벨(Python)에서 이를 제어하면 동시성 문제(Race Condition)로 데이터가 꼬일 위험이 큼.
  - Resolution Strategy: [DB-Level Constraints & RPC Transaction]
  - 구체적 구현 (Implementation):
      - Constraint: `CHECK (film_revenue >= 0)` 및 `CHECK (film_free >= 0)` 제약 조건을 DB 컬럼에 직접 걸어, 어떤 버그가 발생해도 마이너스 잔고가 되는 것을 물리적으로 차단.
      - Atomic RPC: 잔고 차감 로직은 반드시 Supabase RPC(PostgreSQL Function) 내부에서 `BEGIN ... COMMIT` 트랜잭션으로 처리. (Python에서 `update` 호출 금지).
      - Priority: 소비 시 `film_free`가 먼저 차감되고, 부족할 때만 `film_revenue`가 차감되는 로직을 RPC 내부에 하드코딩.

[3단계: 심화 및 최적화] The Zero-Sum Watchdog (장부 대사 자동화)

  - Conflict: 시스템 오류나 해킹으로 인해 DB상의 잔고 숫자가 조작될 가능성(SQL Injection 등)이 존재함.
  - Resolution Strategy: [Daily Ledger Reconciliation (일일 대사)]
  - 구체적 구현 (Implementation):
      - Logic: 매일 새벽 04:00(KST), `pg_cron`이 다음 수식을 검증.
          - `User Current Balance` == `SUM(All Transaction History)`
      - Action: 단 1원이라도 불일치하는 계정이 발견되면, 해당 계정의 `status`를 즉시 `FROZEN`으로 변경하고 슬랙(Slack)으로 'Critical Alert' 발송.

5.5 Special Extensions (특수 기능 확장) [NEW]

목표: 커머스 수익(D07)과 광고 보안(D10)을 위한 필수 DB 확장 모듈을 탑재하되, 성능 저하와 보안 구멍을 0으로 만든다.

[1단계: 기초 공사] The Toolbox Setup (확장 모듈 장착)

  - Conflict: PostgreSQL 기본 기능만으로는 '이미지 유사도 검색'과 'RSA 서명 검증'이 불가능함.
  - Resolution Strategy: [Extension Management Lifecycle]
  - 구체적 구현 (Implementation):
      - Vector: `CREATE EXTENSION IF NOT EXISTS vector;` (Supabase 지원 확인 필수).
      - Crypto: `CREATE EXTENSION IF NOT EXISTS pgcrypto;` (암호화 및 서명 검증용).
      - Safety: 마이그레이션 스크립트에 `IF NOT EXISTS`를 반드시 포함하여, 배포 시 이미 설치된 환경에서 에러가 나는 것을 방지.

[2단계: 구현 및 확장] Logic Implementation (비즈니스 로직 연결)

  - Conflict: 
    1) 수만 개의 상품 중 비슷한 것을 어떻게 0.1초 만에 찾는가? (D07)
    2) 해커가 가짜 '광고 시청 완료' 패킷을 보내면 어떻게 막는가? (D10)
  - Resolution Strategy: [Embedding Storage & SSV Logic]
  - 구체적 구현 (Implementation):
      - AI Commerce (D07): `items` 테이블에 `embedding vector(512)` 컬럼 추가. Python 서버(CLIP 모델)가 이미지를 512차원 숫자로 변환하여 저장.
      - Ad Security (D10): `pgcrypto`의 `pgp_pub_decrypt_verify` 함수를 사용하여, 광고 네트워크(Google/Unity)가 보낸 서명(Signature)이 진짜인지 DB 레벨에서 검증.

[3단계: 심화 및 최적화] Performance & Anti-Replay (성능 및 재전송 방지)

  - Conflict: 
    1) 데이터가 쌓이면 벡터 검색 속도가 느려져서 쇼핑몰이 버벅거림 (Full Scan).
    2) 해커가 '진짜 서명된 패킷'을 가로채서 100번 재전송(Replay Attack)하면 보상이 100번 지급됨.
  - Resolution Strategy: [HNSW Indexing & Idempotency Check]
  - 구체적 구현 (Implementation):
      - Vector Indexing: `CREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);` -> HNSW 인덱스를 통해 100만 건 중에서도 0.01초 내 검색 보장.
      - Anti-Replay: `ad_callbacks` 테이블에 `transaction_id`를 PK(Primary Key) 또는 Unique Index로 설정. 동일한 ID의 요청이 다시 들어오면 DB가 즉시 에러(Duplicate Key)를 뱉고 무시함.

✅ [Section 5. 최종 무결성 점검표]

1. Automation & Reliability (자동화 신뢰성)
  - [ ] [Audit] 모든 크론 작업의 성공/실패/소요시간이 cron_audit_logs에 기록되는가?
  - [ ] [Alert] 배치 실패 시 pg_net을 통해 관리자에게 즉시 알림이 가는가?
  - [ ] [Lock] Advisory Lock을 통해 배치의 중복 실행 가능성을 0%로 만들었는가?

2. Data Pipeline Safety (데이터 파이프라인 안전성)
  - [ ] [Decoupling] 매거진 아카이브는 원본 데이터(Post) 삭제와 완전히 독립적인가? (Deep Copy 확인)
  - [ ] [Isolation] 매거진 이미지는 물리적으로 별도 버킷(magazine_archive)에 저장되는가?
  - [ ] [Atomic] 매거진 공개는 is_published 플래그를 통해 트랜잭션 단위로 원자적으로 수행되는가?
  - [ ] [Cleanup] 고아 파일(Orphan File) 삭제 로직이 Full Scan이 아닌 Index Scan을 타도록 최적화되었는가?

3. Business Logic Integrity (비즈니스 로직 무결성)
  - [ ] [Justice] AI 사법 시스템은 신고 후 24시간이라는 방어권을 시스템적으로 보장하는가?
  - [ ] [Ledger] 매일 새벽 '잔고'와 '거래 내역 총합'을 대조하는 무결성 검증 크론이 활성화되었는가? (D07/D13 연결)
  - [ ] [Recursive] 족보 추적 쿼리(WITH RECURSIVE)에 무한 루프 방지용 MAX_DEPTH 제한이 걸려있는가? (D11 연결)

4. Extension & Security (확장 및 보안 - NEW)
  - [ ] [Index] AI 커머스용 벡터 컬럼에 HNSW 인덱스가 적용되어 Full Scan을 방지하는가? (D07 연결)
  - [ ] [Idempotency] 광고 보상 테이블에 transaction_id 유니크 제약 조건이 걸려있어 재전송 공격(Replay Attack)을 막는가? (D10 연결)
  - [ ] [Signature] 광고 서버 사이드 검증(SSV) 로직이 DB 함수 내에서 수행되는가?

5. System Baseline (시스템 기본)
  - [ ] [Backup] 데이터뿐만 아니라 스키마와 트리거까지 포함된 Full Dump가 매일 수행되는가?
  - [ ] [Timezone] DB의 Timezone이 UTC로 고정되어 썸머타임/시간대 버그가 없는가?

[Dresaps] Domain 13: Infrastructure - Section 6. CI/CD & Deployment Pipeline

작성일: 2026-02-08
전제 조건: EAS (Expo Application Services), GitHub Actions, Sentry, Supabase CLI.
목표: Human Error 0%, 무중단 배포, 공급망 보안, DB 정합성 보장, 자산 최적화 강제.

6.1 EAS 프로필 및 빌드 아키텍처 (EAS Profiles & Architecture)

[1단계: 기초 공사] The Trinity Profiles (환경의 물리적/논리적 격리)

목표: 개발, 검증, 배포 환경을 섞이지 않게 완벽히 분리하고, 각 단계의 목적에 맞는 최적화 옵션을 강제한다.

  - eas.json Configuration (Detailed):
    1.  development (Debug):
          - Distribution: internal (Simulator/Emulator).
          - Env: .env.development.
          - Client: developmentClient: true (커스텀 런타임 사용 - 개발 속도 가속).
          - iOS Config: resourceClass: "m1-medium" (Apple Silicon 활용으로 빌드 속도 40% 단축).
          - Cache: cache: { key: "dev-dependencies" }.
    2.  preview (Staging):
          - Distribution: internal (등록된 기기 설치 가능).
          - Env: .env.staging.
          - Update Channel: preview.
          - Artifact: APK (Android), Ad-hoc IPA (iOS).
          - Optimization: shrinkResources: true (안 쓰는 리소스 제거).
    3.  production (Release):
          - Distribution: store (App Store / Play Store).
          - Env: .env.production.
          - Update Channel: production.
          - Artifact: AAB (Android App Bundle) (유저 기기에 맞는 리소스만 다운로드 - 앱 크기 30% 감소), IPA (iOS).
          - Compiler: Bytecode Compilation ON (JS 파싱 시간 제거, 초기 구동 속도 2배 향상).
          - Engine: Hermes Release Mode (메모리 최적화).
          - Obfuscation: Proguard/R8 ON (안드로이드 코드 난독화, 리버스 엔지니어링 방지).
  - 32. [O-05] 로컬 빌드 환경 파편화 vs 인프라 표준 준수:
      - Conflict: "내 PC에선 되는데 서버에선 안 돼요" 현상 방지를 위해, 인프라는 엄격한 로컬 빌드 환경을 요구함. (특정 파이썬 버전 등)
      - Resolution Strategy: [Dockerized Build Agent]
      - 구체적 구현 (Implementation):
          - Containerize: 프로젝트 루트에 Dockerfile.builder를 포함시킵니다. 이 안에 파이썬 버전, 라이브러리, 환경 변수 설정을 완벽하게 정의합니다.
          - Script: build.sh 스크립트를 실행하면, 로컬 PC에 도커 컨테이너를 띄우고 그 안에서 빌드를 수행한 뒤 결과물만 뱉어냅니다.
          - Standard: 윈도우, 맥, 리눅스 어떤 OS를 쓰든 빌드 환경은 100% 동일해집니다.
      - 효율(Efficiency): 신규 개발자가 들어와도 환경 설정에 시간 낭비할 필요 없음.
      - 안전성(Safety): 로컬 빌드 결과물과 프로덕션 배포 결과물의 바이너리 일치(Binary Consistency) 보장.

[2단계: 확장 및 자동화] Submit Automation & Upload Optimization (제출 및 업로드 최적화)

목표: 빌드 서버로 전송되는 패킷 하나까지 통제하여 시간을 단축하고, 사람의 손을 없앤다.

  - Upload Diet (.easignore):
      - Action: 프로젝트 루트에 .easignore 파일 생성.
      - Content: .git, node_modules, *.mp4, design_assets/, *.orig, .DS_Store, tests/.
      - Effect: 빌드 서버로 전송되는 압축 파일 크기를 500MB -> 50MB로 줄임. (대기 시간 90% 단축).
  - Submit Profiles (Zero-Touch):
      - Android:
          - track: "internal" (내부 테스트 트랙 자동 업로드).
          - releaseStatus: "draft" (즉시 배포 방지).
          - changesNotSentForReview: true.
      - iOS:
          - ascAppId: (Apple App ID).
          - appleId: (Developer Account).
          - Dest: TestFlight (자동 업로드 및 테스터에게 즉시 알림).
  - Auto-Increment Strategy:
      - Config: eas.json -> "autoIncrement": true.
      - Logic: 로컬의 versionCode를 무시하고, EAS 서버의 원자적 카운터(Atomic Counter)를 사용. 버전 충돌 수학적 불가능.

[3단계: 보안 심화 및 최적화] Runtime Version Policy (네이티브 충돌 방지)

목표: OTA(Over-The-Air) 업데이트 시 네이티브 코드 불일치로 인한 앱 크래시(White Screen)를 수학적으로 차단한다.

  - Policy: Fingerprint (지문 인식):
      - Config: app.json -> "runtimeVersion": { "policy": "fingerprint" }.
      - Logic: 프로젝트 내의 네이티브 폴더(ios, android)와 package.json의 네이티브 모듈 의존성 트리를 해시(Hash)값으로 변환.
      - Action: 앱 실행 시, 서버의 런타임 해시와 내 앱의 해시가 1비트라도 다르면 업데이트 다운로드 거부.
      - Effect: 네이티브 코드가 변경된 업데이트를 구버전 앱이 억지로 받아 실행하다 죽는 현상 0%.

6.2 시크릿 및 환경 변수 무결성 (Secrets & Integrity)

[1단계: 기초 공사] Strict Registry & Masking (엄격한 등록 및 마스킹)

목표: 소스코드에는 껍데기만 남기고, 알맹이(Key)는 EAS 서버 금고에만 둔다. CI 로그에서도 숨긴다.

  - Registry Rule:
      - Client-Side Public: EXPO_PUBLIC_ 접두사 사용 (예: EXPO_PUBLIC_SUPABASE_URL). 빌드 타임에 JS 번들에 주입(Substitution).
      - Build-Time Secret: GOOGLE_SERVICES_JSON, SENTRY_AUTH_TOKEN. (파일 형태의 시크릿은 Base64로 인코딩하여 EAS Secret에 저장 후 빌드 직전 디코딩).
  - Log Masking:
      - Action: GitHub Actions Settings -> Secrets.
      - Effect: 빌드 스크립트가 실수로 console.log(process.env)를 해도, 로그에는 ****로 마스킹되어 출력됨.

[2단계: 확장 및 자동화] Environment Parity Check (Fail-Fast 검증)

목표: "환경 변수 누락으로 빌드가 터져서 30분과 크레딧을 날리는" 상황을 1초 만에 감지한다.

  - Pre-build Hook:
      - Script: scripts/check-env.js.
      - Hook: package.json -> "prebuild": "node scripts/check-env.js".
      - Logic:
        1.  .env 파일 로드 (로컬) 또는 시스템 환경 변수 로드 (CI).
        2.  필수 키 리스트(EXPO_PUBLIC_SUPABASE_URL, EXPO_PUBLIC_...)와 대조.
        3.  하나라도 누락되거나 빈 값이면 process.exit(1) (즉시 강제 종료).

[3단계: 보안 심화 및 최적화] Supply Chain Security (공급망 보안)

목표: 해커가 오픈소스 라이브러리를 오염시켜 배포하는 것을 막는다.

  - Deterministic Installation (npm ci):
      - Action: CI 파이프라인에서 npm install 대신 반드시 npm ci 사용.
      - Effect: package-lock.json에 기록된 해시값과 정확히 일치하는 패키지만 설치. (잠재적 버전 업그레이드 차단).
  - Dependency Audit:
      - Command: npm audit --production --audit-level=high.
      - Logic: 심각한 보안 취약점(High/Critical)이 발견되면 빌드 프로세스 중단.
  - Code Signing (위변조 방지):
      - Setup: npx expo-updates codesigning:generate.
      - Verification: 앱이 OTA 업데이트를 받을 때, 서명을 검증하여 위변조되었거나 해커가 만든 업데이트라면 설치 거부 및 롤백.

6.3 버전 관리 및 업데이트 전략 (Versioning & Strategy)

[1단계: 기초 공사] Semantic Versioning (의미론적 버전 관리)

목표: 버전 숫자만 봐도 호환성을 알 수 있게 한다.

  - Rule: Major.Minor.Patch (예: 1.0.0).
      - Major: 네이티브 코드 대격변 / 하위 호환 불가. (스토어 배포 필수).
      - Minor: 기능 추가 / 네이티브 변경 포함. (스토어 배포 권장).
      - Patch: JS/Asset 수정 / 버그 픽스. (OTA 배포 가능).

[2단계: 확장 및 자동화] Channel Promotion (채널 승격 전략)

목표: 검증된 빌드를 다시 빌드하지 않고 그대로 상용으로 보낸다. (Build Once, Deploy Anywhere).

  - Flow:
    1.  개발자가 preview 채널로 업데이트 배포 -> QA 팀 검증 완료.
    2.  Republish (X) -> Promote (O):
    3.  Command: eas update:configure --channel production --branch main.
    4.  Effect: preview에서 검증된 그 바이너리(해시값 동일)가 그대로 production 유저에게 배포됨. 재빌드로 인한 버그 발생 가능성 0%.

[3단계: 보안 심화 및 최적화] Emergency Rollback & Break-Glass (비상 대응)

목표: 잘못된 배포를 취소하고, EAS 서버가 다운되었을 때도 배포할 수 있어야 한다.

  - Rollback Strategy:
      - Command: eas update:rollback --channel production.
      - Logic: 해당 채널의 포인터를 이전 업데이트 그룹 ID로 되돌림.
      - Client Action: 앱을 껐다 켜는 순간 즉시 이전 버전으로 롤백됨. (재설치 불필요).
  - Break-Glass Protocol (EAS 장애 시):
      - Scenario: EAS 서버가 다운되어 클라우드 빌드 불가.
      - Action: eas build --local --profile production.
      - Requirement: 개발자 로컬 머신에 Android Studio / Xcode, 그리고 credentials.json 백업본이 준비되어 있어야 함.

6.4 GitHub Actions 파이프라인 (The Automation Engine)

[1단계: 기초 공사] Quality Gate & Smart Caching (품질 관문 및 캐싱)

목표: 쓰레기 코드 차단 및 빌드 시간 50% 단축.

  - Concurrency Group:
      - Config: concurrency: group: ${{ github.ref }} cancel-in-progress: true.
      - Effect: 개발자가 커밋을 3번 연속 푸시하면, 앞선 2개의 빌드는 즉시 취소. (CI 비용/시간 절약).
  - Cache Busting Strategy:
      - Logic: 커밋 메시지에 [no cache]가 포함되어 있으면 캐시 로드 스킵.
      - Why: 캐시가 오염(Corrupted)되어 빌드가 계속 실패할 때, 강제로 클린 빌드를 수행하기 위함.
  - Expo Doctor (호환성 검증):
      - Step: npx expo-doctor.
      - Effect: 패키지 버전 간의 충돌이나 Expo SDK와의 호환성 문제를 빌드 전에 사전 감지 및 차단.

[2단계: 확장 및 자동화] DB Schema & Asset Gate (정합성 및 자산 검문소)

목표: 코드는 나갔는데 DB 컬럼이 없어서 터지는 사고와, 거대 이미지로 인한 성능 저하를 막는다.

  - Step 0: DB Schema Check (CRITICAL):
      - Command: supabase db push --dry-run.
      - Logic: 현재 마이그레이션 파일이 실제 DB와 충돌하는지, 혹은 로컬 스키마 변경 사항이 마이그레이션 파일로 생성되지 않았는지 검사.
      - Action: 불일치 시 빌드 실패. (코드와 DB의 싱크 강제).
  - Step 0.5: Asset Optimization Guard:
      - Command: npx expo-optimize.
      - Logic: 프로젝트 내의 모든 이미지를 스캔하여 압축되지 않은 고용량 이미지가 있으면 WebP로 변환 및 압축 수행.
      - Validation: 1MB 이상의 단일 이미지가 발견되면 빌드 경고(Warning) 또는 실패(Fail) 처리.

[3단계: 보안 심화 및 최적화] Sentry Stealth Mode & Notifications (은폐 및 알림)

목표: 디버깅은 하고 싶지만, 내 코드를 해커에게 보여줄 순 없다. 그리고 결과를 즉시 안다.

  - Security Pipeline:
      - Step 1 (Generate): 빌드 도중 소스맵(.map) 생성.
      - Step 2 (Upload): sentry-expo-upload-sourcemaps로 Sentry 비공개 서버에 업로드. (커밋 해시와 연동).
      - Step 3 (Destroy - CRITICAL): rm -rf **/*.map. (번들링 직후, 업로드 완료 후 즉시 삭제).
      - Effect: Sentry 대시보드에서는 원본 코드로 에러 위치가 보이지만, 해커가 앱을 뜯어보면 알 수 없는 문자열만 보임.
  - 27. [C-05] 소스맵(Source Map) 파기 vs 에러 디버깅:
      - Conflict: 보안 규정상 프로덕션 배포 시 소스맵을 삭제함. 에러 로그가 a.js:1:4023 같이 암호문처럼 나와 디버깅 불가능.
      - Resolution Strategy: [Structured Context Logging (문맥 로깅)]
      - 구체적 구현 (Implementation):
          - Structure: 에러 발생 위치(Stack Trace)에 의존하지 않습니다.
          - Breadcrumbs: 유저가 어떤 경로로 들어왔는지(화면 이동 기록), 직전에 누른 버튼은 무엇인지 로그 객체에 담습니다.
          - State: 에러 발생 순간의 주요 변수 상태(State Snapshot)를 JSON으로 함께 전송합니다.
          - Spec: { "error": "NullPointer", "action": "checkout_btn_click", "cart_items": 3, "user_grade": "vip" }
      - 효율(Efficiency): 코드를 역추적하는 것보다 유저 행동을 재현(Replay)하는 것이 버그 수정 속도가 2배 빠름.
      - 안전성(Safety): 소스 코드는 여전히 숨겨져 있어 보안성 유지.
  - Slack Notification:
      - Action: 빌드 성공/실패 시 Slack 웹훅 호출.
      - Content: 빌드 상태, 커밋 메시지, 작성자, EAS 대시보드 링크, QR 코드(Preview용) 포함.

✅ [Section 6. 최종 무결성 점검표]

1.  [ ] [Ignore] .easignore가 설정되어 .git, node_modules 등 불필요한 에셋 업로드를 차단하는가?
2.  [ ] [Profiles] development, preview, production 환경이 물리적/논리적으로 완벽히 격리되어 있는가?
3.  [ ] [Fingerprint] runtimeVersion: fingerprint 설정으로 네이티브 충돌을 수학적으로 차단했는가?
4.  [ ] [Schema] supabase db push --dry-run을 통해 코드와 DB 스키마의 불일치를 빌드 전에 감지하는가?
5.  [ ] [Asset] npx expo-optimize가 실행되어 고용량 이미지가 빌드에 포함되는 것을 막는가?
6.  [ ] [Secrets] EXPO_PUBLIC_ 외의 시크릿 키가 클라이언트 번들에 포함되지 않도록 검증했는가?
7.  [ ] [Signing] Code Signing이 적용되어 위변조된 업데이트 설치를 거부하는가?
8.  [ ] [Fail-Fast] 환경 변수 누락 시 빌드가 시작되기 전에(0초 시점) 즉시 실패하는가?
9.  [ ] [Integrity] npm ci와 expo-doctor를 통해 공급망 공격과 호환성 문제를 막는가?
10. [ ] [Stealth] 소스맵이 Sentry 업로드 후 물리적으로 삭제(rm -rf)되어 코드 유출을 막는가?
11. [ ] [Automation] auto-submit을 통해 빌드부터 스토어 제출까지 사람의 개입 없이(Zero-Touch) 진행되는가?
12. [ ] [Resilience] EAS 서버 다운 시 local build로 대응할 수 있는 Break-Glass 프로토콜이 존재하는가?
13. [ ] [Recovery] 캐시 오염 시 [no cache] 커밋 메시지로 강제 클린 빌드가 가능한가?

[Dresaps] Domain 13: Infrastructure - Section 7. Monitoring & Observability

작성일: 2026-02-08
전제 조건: Sentry, Firebase Analytics, UptimeRobot, Supabase Logs.
목표: 장애 감지 1분 미만, 기기 발열/배터리 최적화, 내부 통제(Audit), 예산 방어율 100%.

7.1 로깅 아키텍처 및 제로 오버헤드 정책 (Zero-Overhead Logging)

[1단계: 기초 공사] The Global Override & Offline Queue

목표: 개발 로그 완전 차단 및 오프라인 로그 보존.

  - Babel Transform: babel-plugin-transform-remove-console로 console.* 코드 물리적 삭제.
  - Persistent Queue: 네트워크 단절 시 로그를 로컬 스토리지에 암호화 저장, 재연결 시 자동 전송 (Sentry Cache).

[2단계: 확장 및 자동화] Distributed Tracing (분산 추적)

목표: 클라이언트-서버-DB를 관통하는 에러 추적.

  - Trace ID: x-request-id 헤더에 UUID 주입하여 전체 트랜잭션 흐름 시각화.

[3단계: 보안 심화 및 최적화] PII Deep Scrubbing

목표: 개인정보 유출 원천 차단.

  - Scrubber: password, token, email, card 등 민감 키를 [REDACTED]로 재귀적 치환.
  - Visual Privacy: Session Replay 시 텍스트/이미지 마스킹(maskAll) 강제.

7.2 에러 트래킹 및 자율 방어 (Self-Healing Error Tracking)

[1단계: 기초 공사] Full-Stack Capture

목표: JS 및 네이티브 크래시 수집.

  - Scope: React Native JS Error + Android/iOS Native Crash + Asset Loading Error.

[2단계: 확장 및 자동화] Smart Backoff & Circuit Breaker

목표: 장애 확산 방지.

  - Backoff: 서버 429/503 응답 시 5분간 로그 전송 중단.
  - Circuit Breaker: 동일 에러 1분 내 5회 발생 시 로컬에서 차단.

[3단계: 보안 심화 및 최적화] Dynamic Alerting

목표: 알림 피로도 제거 및 중요도별 라우팅.

  - P1 (Critical): 결제/로그인 실패, 에러 급증 -> 전화/SMS.
  - P2 (Warning): 신규 이슈, 성능 저하 -> Slack.

7.3 비즈니스 분석 및 성능 관측 (Analytics & Performance)

[1단계: 기초 공사] Core Events Schema

목표: 데이터 정합성 확보.

  - Naming: [Object]_[Action]_[Status] 규칙 준수.
  - Funnel: 앱 실행 -> 가입 -> 스캔 -> 생성 -> 공유.

[2단계: 확장 및 자동화] Synthetic User Monitoring

목표: 24시간 무중단 기능 점검.

  - Bot: 매시 정각 봇이 '무료 생성 API'를 호출하여 E2E 테스트 수행. 실패 시 즉시 알림.

[3단계: 보안 심화 및 최적화] Privacy Compliance

목표: ATT 및 GDPR 준수.

  - Logic: iOS 추적 거부 시 Analytics 수집 즉시 중단 코드 내장.

7.4 인프라 헬스 및 예산 방어 (Health & Budget)

[1단계: 기초 공사] Deep Health Check

목표: 좀비 서버 탐지.

  - Logic: API 호출 + DB 쿼리 + 스토리지 쓰기 권한을 통합 체크하는 /health-deep 엔드포인트 운영.

[2단계: 확장 및 자동화] Budget Forecasting

목표: 예산 소진 사전 예측.

  - Forecast: 현재 속도 기반 월말 예상 사용량 계산 -> 90% 초과 예측 시 경고.

[3단계: 보안 심화 및 최적화] Feature Kill Switch

목표: 과금 폭탄 및 치명적 버그 즉시 차단.

  - Config: enable_ai_generation 플래그를 원격(Supabase)에서 제어하여 앱 재배포 없이 기능 On/Off.

7.5 기기 바이탈 및 보안 감사 (Device Vital & Security Audit) [NEW]

[1단계: 기초 공사] Thermal & Battery Monitoring (발열 감지)

목표: 고사양 작업(AI/3D)으로 인한 폰 과열 및 배터리 광탈을 감지한다.

  - 30. [O-03] 발열 모니터링 vs 스토어 심사 거부(Rejection):
      - Conflict: 앱이 기기 온도(예: 42.5도)를 수집하면 애플/구글은 "과도한 개인정보/기기정보 수집"이라며 앱 등록을 거부함.
      - Resolution Strategy: [Abstracted Categorical Reporting]
      - 구체적 구현 (Implementation):
          - Local Check: 앱 내부적으로는 온도를 float 값으로 측정합니다.
          - Convert: 서버로 보낼 때는 숫자를 버리고 **추상화된 등급(Enum)**으로 변환합니다.
          - Temp < 35: "GREEN"
          - 35 < Temp < 40: "YELLOW"
          - Temp > 40: "RED"
          - Send: 서버에는 오직 "RED"라는 문자열만 전송됩니다.
      - 효율(Efficiency): 앱 성능 최적화에 필요한 정보는 얻으면서, 개인정보 이슈는 회피.
      - 안전성(Safety): 스토어 심사관에게 "우리는 구체적 수치를 수집하지 않는다"고 소명 가능.
  - Memory Warning: onMemoryWarning 이벤트 발생 시점을 기록하여 OOM(Out of Memory) 크래시 원인 추적.

[2단계: 확장 및 자동화] Security Audit Trails (보안 감사)

목표: "누가 관리자 패널에서 유저 데이터를 조회했는가?"를 기록한다.

  - 29. [O-02] 감사 로그(Audit Log) 수정 불가 vs 운영 실수 정정:
      - Conflict: 한 번 기록된 로그는 절대 수정/삭제 불가(WORM). 운영자가 실수로 유저를 차단해도 기록을 지울 수 없음.
      - Resolution Strategy: [Contra-Entry Pattern (상계 처리)]
      - 구체적 구현 (Implementation):
          - Prohibit: DELETE FROM logs 쿼리는 아예 작성하지 않습니다.
          - Insert: 실수가 발생하면 type: 'CORRECTION', ref_id: '이전_로그_ID', reason: '오조작 철회'가 담긴 새로운 로그를 쌓습니다.
          - View: 관리자 대시보드에서는 원본 로그와 정정 로그를 합산하여, 최종 상태(차단 해제됨)만 보여줍니다.
      - 효율(Efficiency): 금융권(은행) 회계 장부 시스템과 동일. 데이터 신뢰도 최상.
      - 안전성(Safety): "누가 언제 실수를 했고, 언제 바로잡았는지"까지 투명하게 남음.

[3단계: 보안 심화 및 최적화] Network Payload Monitoring (데이터 소모량)

목표: 유저의 데이터 요금을 지켜준다.

  - Payload Size Tracking:
      - Interceptor: 모든 API 응답의 Content-Length를 합산 추적.
      - Warning: 단일 세션에서 50MB 이상 소모 시 경고 로그 전송 (비정상적인 이미지 다운로드 루프 감지).

✅ [Section 7. 최종 무결성 점검표]

1.  [ ] [Zero Console] 프로덕션에서 콘솔 로그가 바이트코드 레벨에서 삭제되는가?
2.  [ ] [Offline] 네트워크 단절 시 로그를 보존하고 재연결 시 전송하는가?
3.  [ ] [Trace ID] 전 구간 분산 추적(Distributed Tracing)이 적용되었는가?
4.  [ ] [Scrubbing] PII(개인정보)가 텍스트 및 시각적(Replay)으로 완벽히 마스킹되는가?
5.  [ ] [Thermal] 기기 발열 상태(thermalState)와 메모리 경고를 기록하여 크래시 원인을 분석하는가? (Critical)
6.  [ ] [Audit] 관리자의 주요 작업이 위변조 불가능한 audit_logs 테이블에 기록되는가? (Critical)
7.  [ ] [Backoff] 서버 장애 시 클라이언트가 스스로 요청을 줄이는가?
8.  [ ] [Synthetic] 봇이 주기적으로 실제 기능을 테스트하여 24시간 감시하는가?
9.  [ ] [Payload] 비정상적인 데이터 소모량을 감지하는 로직이 있는가?
10. [ ] [Kill Switch] 예산/장애 시 기능을 즉시 차단할 수 있는가?